{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Red Neuronal Profunda (DNN) para clasificación MNIST\n",
    "\n",
    "Aplicaremos todos nuestros conocimientos para crear una DNN, frecuentemente llamada también una Artificial Neural Network (ANN).  El problema que vamos a trabajar se conoce como el \"Hola Mundo\" del aprendizaje profundo porque para la mayoría de estudiantes este es el primer algoritmo de aprendizaje profundo que ven. \n",
    "\n",
    "El conjunto de datos se llama MNIST y se refiere al reconocimiento de dígitos escritos a mano.  Pueden encontrar más información en el sitio web de Yann LeCun (Director of AI Research, Facebook).  El es uno de los pioneros de todo este tema, así como de otras metodologías más complejas como las Redes Neurales Convolucionales (CNN) que se utilizan hoy día.\n",
    "\n",
    "El conjunto de datos tiene 70,000 imágenes (28x28 pixels) de dígitos escritos a mano (1 dígito por imagen).\n",
    "\n",
    "La meta es escribir un algoritmo que detecta qué dígito ha sido escrito.  Como solo hay 10 dígitos (0 al 9), este es un problema de clasificación con 10 clases.\n",
    "\n",
    "Nuestra meta será construir una RN con 2 capas escondidas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importar los paquetes relevantes\n",
    "\n",
    "TensorFlow incluye un proveedor de datos de MNIST que utilizaremos acá.  Viene con el módulo **\"tensorflow.keras.datasets\"**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La siguiente instrucción, cuando se corre por primera vez, descarga el conjunto de datos en lo indicado por el parámetro path, relativo a  ~/.keras/datasets).  Como si se hubiera ejecutado Lo siguiente:\n",
    "\n",
    "tf.keras.datasets.mnist.load_data(\n",
    "    path='mnist.npz'\n",
    ")\n",
    "\n",
    "luego separa los datos en un conjunto para entrenamiento y otro para pruebas.\n",
    "\n",
    "Si se ejecuta más de una vez, ya no descarga el archivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_entreno, y_entreno), (X_prueba, y_prueba) = tf.keras.datasets.mnist.load_data()\n",
    "assert X_entreno.shape == (60000, 28, 28)\n",
    "assert X_prueba.shape == (10000, 28, 28)\n",
    "assert y_entreno.shape == (60000,)\n",
    "assert y_prueba.shape == (10000,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datos\n",
    "\n",
    "Esta sección es donde pre-procesaremos nuestros datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por default, TF2 tiene conjuntos de datos de entrenamiento y de prueba, pero no tiene un conjunto de validación, por lo que debemos dividirlo por nuestra cuenta\n",
    "\n",
    "Lo haremos del mismo tamaño que el conjunto de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_obs_validacion = y_prueba.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usaremos una variable dedicada para el número de muestras de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_obs_prueba = y_prueba.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generalmente preferimos \"normalizar\" nuestros datos en alguna forma para que el resultado sea numéricamente más estable.  En este caso simplemente preferimos tener entradas entre 0 y 1, por lo que definimos una función, que reciba la imagen MNIST.\n",
    "\n",
    "Como los posibles valores de las entradas son entre 0 y 255 (256 posibles tonos de gris), al dividirlos por 255 obtenemos el resultado deseado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_entreno_normalizado = X_entreno / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, normalizaremos y convertiremos los datos de pruebas en tandas.  Los normalizamos para que tengan la misma magnitud que los datos de entrenamiento y validación.\n",
    "\n",
    "No hay necesidad de \"barajearlo\" ya que no estaremos entrenando con los datos de prueba.  Habra una sola tanda, igual al tamaño de los datos de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_prueba_normalizado = X_prueba / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez se han \"normalizado\" los datos, podemos proceder a extraer los datos de entrenamiento y de validación.\n",
    "\n",
    "Nuestros datos de validación serán 10000 para ser igual al conjunto de prueba.\n",
    "\n",
    "Finalmente, creamos una tanda con un tamaño de tanda igual al total de muestras de validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_validacion = X_entreno_normalizado[-num_obs_validacion: , : , : ]\n",
    "y_validacion = y_entreno[-num_obs_validacion:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarmente, los datos de entrenamiento son todos los demás por lo que nos salteamos tantas observaciones como las hay en el conjunto de validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_entreno = X_entreno_normalizado[ : X_entreno_normalizado.shape[0] - num_obs_validacion, : , : ]\n",
    "y_entreno = y_entreno[ : y_entreno.shape[0] - num_obs_validacion]\n",
    "num_obs_entreno = y_entreno.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convertir de Arreglos Numpy a Tensores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_entreno = tf.data.Dataset.from_tensor_slices((X_entreno, y_entreno))\n",
    "datos_validacion = tf.data.Dataset.from_tensor_slices((X_validacion, y_validacion))\n",
    "datos_prueba = tf.data.Dataset.from_tensor_slices((X_prueba, y_prueba))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Barajear y hacer tandas con el conjunto de datos de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "TAMANIO_TANDA = 100\n",
    "datos_entreno = datos_entreno.shuffle(buffer_size = num_obs_entreno).batch(TAMANIO_TANDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hacer tandas con los conjunto de validación y prueba, no se necesita barajearlos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_validacion = datos_validacion.batch(TAMANIO_TANDA)\n",
    "datos_prueba = datos_prueba.batch(TAMANIO_TANDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delineamos el modelo\n",
    "\n",
    "Cuando pensamos sobre un algoritmo de aprenzaje profundo, casi siempre solo lo imaginamos.  Asi que esta vez, hagámoslo.  :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tamanio_entrada = 784\n",
    "tamanio_salida = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usaremos el mismo ancho para ambas capas escondidas.  No es una necesidad!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tamanio_capa_escondida = 50\n",
    "# tamanio_capa_escondida = 200\n",
    "# tamanio_capa_escondida = 300\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definimos cómo se verá el modelo\n",
    "\n",
    "La primera capa (la de entrada):  cada observación es de 28x28 píxeles, por lo tanto es un tensor de rango 2.\n",
    "\n",
    "Como aún no hemos aprendido sobre CNNs, no sabemos como alimentar este tipo de entrada a nuestra red, por lo tanto hay que \"aplanar\" las imágenes.  Hay un método conveniente **Flatten** que toma nuestro tensor de 28x28 y lo convierte en  un vector (None), o (784,)...porque 28x28 = 784.  Esto nos permite crear una red de alimentación hacia adelante.\n",
    "\n",
    "    \n",
    "**tf.keras.layers.Dense** básicamente implementa:  output = activation(dot(entrada, peso) + sesgo).  Requiere varios argumentos, pero los más importantes para nosotros son el ancho de la capa escondida y la función de activación.\n",
    "\n",
    "La capa final no es diferente, solo nos aseguramos de activarla con **softmax**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = tf.keras.Sequential([\n",
    "\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)), # capa entrada\n",
    "    \n",
    "    tf.keras.layers.Dense(tamanio_capa_escondida, activation='relu'), # 1era capa escondida\n",
    "    tf.keras.layers.Dense(tamanio_capa_escondida, activation='relu'), # 2nda capa escondida\n",
    "    # tf.keras.layers.Dense(tamanio_capa_escondida, activation='relu'), # 3era capa escondida\n",
    "    # tf.keras.layers.Dense(tamanio_capa_escondida, activation='relu'), # 4ta capa escondida\n",
    "    # tf.keras.layers.Dense(tamanio_capa_escondida, activation='relu'), # 5ta capa escondida\n",
    "    \n",
    "    # tf.keras.layers.Dense(tamanio_capa_escondida, activation='sigmoid'), # 1era capa escondida\n",
    "    # tf.keras.layers.Dense(tamanio_capa_escondida, activation='sigmoid'), # 2nda capa escondida\n",
    "\n",
    "    # tf.keras.layers.Dense(tamanio_capa_escondida, activation='relu'), # 1era capa escondida\n",
    "    # tf.keras.layers.Dense(tamanio_capa_escondida, activation='tanh'), # 2nda capa escondida\n",
    "    \n",
    "    tf.keras.layers.Dense(tamanio_salida, activation='softmax') # capa salida\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seleccionar el optimizador y la función de pérdida"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Definimos el optimizador que nos gustaría utilizar, la función de pérdida, y las métricas que nos interesa obtener en cada interacción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento\n",
    "\n",
    "Acá es donde entrenamos el modelo que hemos construído\n",
    "\n",
    "Determinamos el número máximo de épocas.\n",
    "\n",
    "Ajustamos el modelo , especificando:\n",
    "\n",
    "* los datos de entrenamiento\n",
    "* el número total de épocas\n",
    "* y los datos de validación que creamos en el formato (entradas, metas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "500/500 - 2s - loss: 0.4348 - accuracy: 0.8783 - val_loss: 0.1981 - val_accuracy: 0.9441 - 2s/epoch - 4ms/step\n",
      "Epoch 2/5\n",
      "500/500 - 1s - loss: 0.1836 - accuracy: 0.9462 - val_loss: 0.1476 - val_accuracy: 0.9574 - 1s/epoch - 2ms/step\n",
      "Epoch 3/5\n",
      "500/500 - 1s - loss: 0.1380 - accuracy: 0.9593 - val_loss: 0.1336 - val_accuracy: 0.9626 - 1s/epoch - 2ms/step\n",
      "Epoch 4/5\n",
      "500/500 - 1s - loss: 0.1129 - accuracy: 0.9660 - val_loss: 0.1247 - val_accuracy: 0.9647 - 1s/epoch - 2ms/step\n",
      "Epoch 5/5\n",
      "500/500 - 1s - loss: 0.0958 - accuracy: 0.9712 - val_loss: 0.1096 - val_accuracy: 0.9697 - 1s/epoch - 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2104a7ac520>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUMERO_EPOCAS = 5\n",
    "\n",
    "modelo.fit(datos_entreno,\n",
    "          epochs = NUMERO_EPOCAS, \n",
    "          validation_data = datos_validacion,\n",
    "          verbose = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probar el modelo\n",
    "\n",
    "Como se discutió en clase, luego del entrenamiento (con los datos de entrenamiento), y la validación (con los datos de validación), probamos el potencial de predicción final de nuestro modelo con el conjunto de datos de prueba que el algoritmo NUNCA ha visto antes.\n",
    "\n",
    "Es muy importante reconocer que estar \"jugando\" con los hiperparámetros sobre-ajusta el conjunto de datos de validación.\n",
    "\n",
    "La prueba es la instancia absolutamente final. Nunca debe probarse el modelo antes de haber completamente ajustado el modelo.\n",
    "\n",
    "Si se ajusta el modelo después de hacer la prueba, se empezará a sobre-ajustar el conjunto de datos de prueba, que echaría \"por los suelos\" el propósito original del mismo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 2ms/step - loss: 17.8462 - accuracy: 0.9665\n"
     ]
    }
   ],
   "source": [
    "perdida_prueba, precision_entrenamiento = modelo.evaluate(datos_prueba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pérdida de prueba: 17.85. Precisión de prueba: 96.65%\n"
     ]
    }
   ],
   "source": [
    "# Si se desea, se puede aplicar un formateo \"bonito\"\n",
    "print('Pérdida de prueba: {0:.2f}. Precisión de prueba: {1:.2f}%'.format(perdida_prueba, precision_entrenamiento * 100.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizando el modelo inicial y los hiperparámetros dados en este notebook, la precisión de prueba final debe ser aproximadamente 97%.\n",
    "\n",
    "Cada vez que se ejecuta el código, se obtiene una precisión diferente debido a la \"barajeada\" de las tandas, los pesos se inicializan en forma diferente, etc.\n",
    "\n",
    "Finalmente, intencionalmente se ha llegado a una solución subóptima, para que puedan tener la oportunidad de mejorarla como ejercicio de laboratorio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encontrando el ancho ideal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Lista de tamaños de capas escondidas para probar\n",
    "# tamanios_capa_escondida = [50, 100, 150, 200, 250, 300]\n",
    "\n",
    "# # Variable para guardar el mejor tamaño de capa escondida\n",
    "# mejor_tamanio = None\n",
    "# mejor_precision_validacion = 0\n",
    "\n",
    "# # Iterar sobre los diferentes tamaños de capa escondida\n",
    "# for tamanio in tamanios_capa_escondida:\n",
    "#     # Definir el modelo con el tamaño de capa escondida actual\n",
    "#     modelo = tf.keras.Sequential([\n",
    "#         tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "#         tf.keras.layers.Dense(tamanio, activation='relu'),\n",
    "#         tf.keras.layers.Dense(tamanio, activation='relu'),\n",
    "#         tf.keras.layers.Dense(tamanio_salida, activation='softmax')\n",
    "#     ])\n",
    "\n",
    "#     # Compilar el modelo\n",
    "#     modelo.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#     # Entrenar el modelo\n",
    "#     historia = modelo.fit(datos_entreno, epochs=NUMERO_EPOCAS, validation_data=datos_validacion, verbose=0)\n",
    "\n",
    "#     # Obtener la precisión de validación final\n",
    "#     precision_validacion = historia.history['val_accuracy'][-1]\n",
    "\n",
    "#     # Imprimir la precisión de validación para este tamaño de capa escondida\n",
    "#     print(f'Tamaño de capa escondida: {tamanio}, Precisión de validación: {precision_validacion:.2f}%')\n",
    "\n",
    "#     # Verificar si este es el mejor tamaño de capa escondida encontrado hasta ahora\n",
    "#     if precision_validacion > mejor_precision_validacion:\n",
    "#         mejor_precision_validacion = precision_validacion\n",
    "#         mejor_tamanio = tamanio\n",
    "\n",
    "# print(f'\\nEl mejor tamaño de capa escondida es {mejor_tamanio} con una precisión de validación de {mejor_precision_validacion:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probando diferentes tamaños de tanda\n",
    "\n",
    "Probamos con tamaños de tanda de 10,000 y de 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Esta celda tarda aprox. 6 min en ejecutarse..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo con tamaño de tanda '10000'... Listo!\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 35.4739 - accuracy: 0.8045\n",
      "Entrenando modelo con tamaño de tanda '1'... "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 33\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEntrenando modelo con tamaño de tanda \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtamanio\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     32\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m---> 33\u001b[0m historia \u001b[38;5;241m=\u001b[39m \u001b[43mmodelo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdatos_entreno\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNUMERO_EPOCAS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatos_validacion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     35\u001b[0m tiempo_entrenamiento \u001b[38;5;241m=\u001b[39m end \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[1;32mc:\\Users\\caste\\anaconda3\\envs\\base9\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\caste\\anaconda3\\envs\\base9\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\caste\\anaconda3\\envs\\base9\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\caste\\anaconda3\\envs\\base9\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\caste\\anaconda3\\envs\\base9\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\caste\\anaconda3\\envs\\base9\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\caste\\anaconda3\\envs\\base9\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\caste\\anaconda3\\envs\\base9\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\caste\\anaconda3\\envs\\base9\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Lista para guardar los resultados\n",
    "results = []\n",
    "\n",
    "# Lista de tamaños de tanda\n",
    "tamanios_tanda = [10000, 1]\n",
    "\n",
    "# Definir el modelo\n",
    "modelo = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(50, activation='relu'),\n",
    "    tf.keras.layers.Dense(50, activation='relu'),\n",
    "    tf.keras.layers.Dense(tamanio_salida, activation='softmax')\n",
    "])\n",
    "    \n",
    "# Compilar el modelo\n",
    "modelo.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "# Iterar sobre los diferentes tamaños de tanda\n",
    "for tamanio in tamanios_tanda:\n",
    "    # Reeestablecer los conjuntos de datos\n",
    "    datos_entreno = tf.data.Dataset.from_tensor_slices((X_entreno, y_entreno))\n",
    "    datos_validacion = tf.data.Dataset.from_tensor_slices((X_validacion, y_validacion))\n",
    "    datos_prueba = tf.data.Dataset.from_tensor_slices((X_prueba, y_prueba))\n",
    "    \n",
    "    # Dividir en tandas los conjuntos de datos\n",
    "    datos_entreno = datos_entreno.shuffle(buffer_size = num_obs_entreno).batch(tamanio)  # Barajear datos de entrenamiento\n",
    "    datos_validacion = datos_validacion.batch(tamanio)\n",
    "    datos_prueba = datos_prueba.batch(tamanio)\n",
    "    \n",
    "    # Entrenar el modelo con los datos divididos\n",
    "    print(f\"Entrenando modelo con tamaño de tanda '{tamanio}'...\", end=\" \")\n",
    "    start = time.time()\n",
    "    historia = modelo.fit(datos_entreno, epochs=NUMERO_EPOCAS, validation_data=datos_validacion, verbose=0)\n",
    "    end = time.time()\n",
    "    tiempo_entrenamiento = end - start\n",
    "    print(\"Listo!\")\n",
    "\n",
    "    # Obtener la pérdida\n",
    "    perdida_prueba, precision_prueba = modelo.evaluate(datos_prueba)\n",
    "\n",
    "    # Obtener la precisión de prueba final\n",
    "    precision_entrenamiento = historia.history['accuracy'][-1]\n",
    "\n",
    "    # Obtener la precisión de validación final\n",
    "    precision_validacion = historia.history['val_accuracy'][-1]\n",
    "\n",
    "    # Guardar los resultados\n",
    "    results.append({\n",
    "        \"Tamaño de tanda\": tamanio,\n",
    "        \"Precisión de entrenamiento\": \"{:.2f}%\".format(precision_entrenamiento * 100),\n",
    "        \"Precisión de prueba\": \"{:.2f}%\".format(precision_prueba * 100),\n",
    "        \"Precisión de validación\": \"{:.2f}%\".format(precision_validacion * 100),\n",
    "        \"Tiempo de entrenamiento (s)\": \"{:.2f}\".format(tiempo_entrenamiento)\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tamaño de tanda</th>\n",
       "      <th>Precisión de entrenamiento</th>\n",
       "      <th>Precisión de prueba</th>\n",
       "      <th>Precisión de validación</th>\n",
       "      <th>Tiempo de entrenamiento (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000</td>\n",
       "      <td>74.10%</td>\n",
       "      <td>79.28%</td>\n",
       "      <td>80.69%</td>\n",
       "      <td>3.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>96.76%</td>\n",
       "      <td>95.89%</td>\n",
       "      <td>96.77%</td>\n",
       "      <td>336.49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Tamaño de tanda Precisión de entrenamiento Precisión de prueba  \\\n",
       "0            10000                     74.10%              79.28%   \n",
       "1                1                     96.76%              95.89%   \n",
       "\n",
       "  Precisión de validación Tiempo de entrenamiento (s)  \n",
       "0                  80.69%                        3.20  \n",
       "1                  96.77%                      336.49  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mostrar resultados como dataframe\n",
    "df = pd.DataFrame(results)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probando diferentes tasas de apredizaje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo con tasa de apredizaje '0.0001'... Listo!\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 27.4773 - accuracy: 0.9394\n",
      "Entrenando modelo con tasa de apredizaje '0.02'... Listo!\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 33.8297 - accuracy: 0.9561\n"
     ]
    }
   ],
   "source": [
    "# Lista para guardar los resultados\n",
    "results = []\n",
    "\n",
    "# Lista de tasas de aprendizaje para probar\n",
    "tasas_aprendizaje = [0.0001, 0.02]\n",
    "\n",
    "# Definir el modelo\n",
    "modelo = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(50, activation='relu'),\n",
    "    tf.keras.layers.Dense(50, activation='relu'),\n",
    "    tf.keras.layers.Dense(tamanio_salida, activation='softmax')\n",
    "])\n",
    "    \n",
    "# Reeestablecer los conjuntos de datos\n",
    "datos_entreno = tf.data.Dataset.from_tensor_slices((X_entreno, y_entreno))\n",
    "datos_validacion = tf.data.Dataset.from_tensor_slices((X_validacion, y_validacion))\n",
    "datos_prueba = tf.data.Dataset.from_tensor_slices((X_prueba, y_prueba))\n",
    "\n",
    "# Dividir en tandas los conjuntos de datos con el tamaño original\n",
    "TAMANIO_TANDA = 100\n",
    "datos_entreno = datos_entreno.shuffle(buffer_size = num_obs_entreno).batch(TAMANIO_TANDA)  # Barajear datos de entrenamiento\n",
    "datos_validacion = datos_validacion.batch(TAMANIO_TANDA)\n",
    "datos_prueba = datos_prueba.batch(TAMANIO_TANDA)\n",
    "    \n",
    "# Iterar sobre las diferentes tasas de aprendizaje\n",
    "for tasa in tasas_aprendizaje:\n",
    "    # Crear el optimizador\n",
    "    optimizador = Adam(learning_rate=tasa)\n",
    "    \n",
    "    # Compilar el modelo con el optimizador\n",
    "    modelo.compile(optimizer=optimizador, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # Entrenar el modelo con los datos divididos\n",
    "    print(f\"Entrenando modelo con tasa de apredizaje '{tasa}'...\", end=\" \")\n",
    "    start = time.time()\n",
    "    historia = modelo.fit(datos_entreno, epochs=NUMERO_EPOCAS, validation_data=datos_validacion, verbose=0)\n",
    "    end = time.time()\n",
    "    tiempo_entrenamiento = end - start\n",
    "    print(\"Listo!\")\n",
    "\n",
    "    # Obtener la pérdida\n",
    "    perdida_prueba, precision_prueba = modelo.evaluate(datos_prueba)\n",
    "\n",
    "    # Obtener la precisión de prueba final\n",
    "    precision_entrenamiento = historia.history['accuracy'][-1]\n",
    "\n",
    "    # Obtener la precisión de validación final\n",
    "    precision_validacion = historia.history['val_accuracy'][-1]\n",
    "\n",
    "    # Guardar los resultados\n",
    "    results.append({\n",
    "        \"Tasa de aprendizaje\": tasa,\n",
    "        \"Precisión de entrenamiento\": \"{:.2f}%\".format(precision_entrenamiento * 100),\n",
    "        \"Precisión de prueba\": \"{:.2f}%\".format(precision_prueba * 100),\n",
    "        \"Precisión de validación\": \"{:.2f}%\".format(precision_validacion * 100),\n",
    "        \"Tiempo de entrenamiento (s)\": \"{:.2f}\".format(tiempo_entrenamiento)\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tasa de aprendizaje</th>\n",
       "      <th>Precisión de entrenamiento</th>\n",
       "      <th>Precisión de prueba</th>\n",
       "      <th>Precisión de validación</th>\n",
       "      <th>Tiempo de entrenamiento (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>93.97%</td>\n",
       "      <td>93.94%</td>\n",
       "      <td>94.38%</td>\n",
       "      <td>12.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0200</td>\n",
       "      <td>96.27%</td>\n",
       "      <td>95.61%</td>\n",
       "      <td>95.86%</td>\n",
       "      <td>12.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Tasa de aprendizaje Precisión de entrenamiento Precisión de prueba  \\\n",
       "0               0.0001                     93.97%              93.94%   \n",
       "1               0.0200                     96.27%              95.61%   \n",
       "\n",
       "  Precisión de validación Tiempo de entrenamiento (s)  \n",
       "0                  94.38%                       12.50  \n",
       "1                  95.86%                       12.01  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mostrar resultados como dataframe\n",
    "df = pd.DataFrame(results)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mejorando la precisión de validación\n",
    "Se modificarán los parámetros y la composición del modelo con el fin de obtener una precisión de validación mayor o igual a 98.5%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establecer parámetros\n",
    "TAMANIO_TANDA = 600\n",
    "TAMANIO_CAPA_ESCONDIDA = 512\n",
    "TASA_APRENDIZAJE = 0.001\n",
    "NUMERO_EPOCAS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo...\n",
      "Epoch 1/20\n",
      "84/84 [==============================] - 2s 14ms/step - loss: 1.0517 - accuracy: 0.7172 - val_loss: 0.3819 - val_accuracy: 0.8982\n",
      "Epoch 2/20\n",
      "84/84 [==============================] - 1s 12ms/step - loss: 0.3450 - accuracy: 0.9026 - val_loss: 0.2730 - val_accuracy: 0.9216\n",
      "Epoch 3/20\n",
      "84/84 [==============================] - 1s 12ms/step - loss: 0.2789 - accuracy: 0.9190 - val_loss: 0.2399 - val_accuracy: 0.9311\n",
      "Epoch 4/20\n",
      "84/84 [==============================] - 1s 12ms/step - loss: 0.2470 - accuracy: 0.9273 - val_loss: 0.2189 - val_accuracy: 0.9344\n",
      "Epoch 5/20\n",
      "84/84 [==============================] - 1s 12ms/step - loss: 0.2182 - accuracy: 0.9362 - val_loss: 0.1922 - val_accuracy: 0.9457\n",
      "Epoch 6/20\n",
      "84/84 [==============================] - 1s 12ms/step - loss: 0.1935 - accuracy: 0.9433 - val_loss: 0.1773 - val_accuracy: 0.9503\n",
      "Epoch 7/20\n",
      "84/84 [==============================] - 1s 12ms/step - loss: 0.1741 - accuracy: 0.9483 - val_loss: 0.1702 - val_accuracy: 0.9516\n",
      "Epoch 8/20\n",
      "84/84 [==============================] - 1s 12ms/step - loss: 0.1562 - accuracy: 0.9535 - val_loss: 0.1537 - val_accuracy: 0.9562\n",
      "Epoch 9/20\n",
      "84/84 [==============================] - 1s 12ms/step - loss: 0.1412 - accuracy: 0.9583 - val_loss: 0.1383 - val_accuracy: 0.9588\n",
      "Epoch 10/20\n",
      "84/84 [==============================] - 1s 12ms/step - loss: 0.1289 - accuracy: 0.9612 - val_loss: 0.1368 - val_accuracy: 0.9610\n",
      "Epoch 11/20\n",
      "84/84 [==============================] - 1s 12ms/step - loss: 0.1156 - accuracy: 0.9661 - val_loss: 0.1253 - val_accuracy: 0.9637\n",
      "Epoch 12/20\n",
      "84/84 [==============================] - 1s 12ms/step - loss: 0.1046 - accuracy: 0.9695 - val_loss: 0.1149 - val_accuracy: 0.9666\n",
      "Epoch 13/20\n",
      "84/84 [==============================] - 1s 12ms/step - loss: 0.0953 - accuracy: 0.9722 - val_loss: 0.1089 - val_accuracy: 0.9681\n",
      "Epoch 14/20\n",
      "84/84 [==============================] - 1s 11ms/step - loss: 0.0861 - accuracy: 0.9748 - val_loss: 0.1064 - val_accuracy: 0.9683\n",
      "Epoch 15/20\n",
      "84/84 [==============================] - 1s 11ms/step - loss: 0.0787 - accuracy: 0.9772 - val_loss: 0.1006 - val_accuracy: 0.9711\n",
      "Epoch 16/20\n",
      "84/84 [==============================] - 1s 12ms/step - loss: 0.0702 - accuracy: 0.9801 - val_loss: 0.0952 - val_accuracy: 0.9706\n",
      "Epoch 17/20\n",
      "84/84 [==============================] - 1s 12ms/step - loss: 0.0633 - accuracy: 0.9818 - val_loss: 0.0964 - val_accuracy: 0.9714\n",
      "Epoch 18/20\n",
      "84/84 [==============================] - 1s 12ms/step - loss: 0.0583 - accuracy: 0.9831 - val_loss: 0.0940 - val_accuracy: 0.9710\n",
      "Epoch 19/20\n",
      "84/84 [==============================] - 1s 12ms/step - loss: 0.0523 - accuracy: 0.9848 - val_loss: 0.0873 - val_accuracy: 0.9744\n",
      "Epoch 20/20\n",
      "84/84 [==============================] - 1s 12ms/step - loss: 0.0475 - accuracy: 0.9869 - val_loss: 0.0874 - val_accuracy: 0.9748\n",
      "Listo!\n",
      "Evaluando modelo...\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.1011 - accuracy: 0.9725\n",
      "Listo!\n"
     ]
    }
   ],
   "source": [
    "# Reestablecer los conjuntos de datos\n",
    "datos_entreno = tf.data.Dataset.from_tensor_slices((X_entreno, y_entreno))\n",
    "datos_validacion = tf.data.Dataset.from_tensor_slices((X_validacion, y_validacion))\n",
    "datos_prueba = tf.data.Dataset.from_tensor_slices((X_prueba, y_prueba))\n",
    "\n",
    "# Dividir en tandas los conjuntos de datos\n",
    "datos_entreno = datos_entreno.shuffle(buffer_size = num_obs_entreno).batch(TAMANIO_TANDA)  # Barajear datos de entrenamiento\n",
    "datos_validacion = datos_validacion.batch(TAMANIO_TANDA)\n",
    "datos_prueba = datos_prueba.batch(TAMANIO_TANDA)\n",
    "\n",
    "# Definimos la nueva estructura del modelo\n",
    "modelo = tf.keras.Sequential([\n",
    "    tf.keras.Input(shape=(28, 28)), # capas de entrada\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(TAMANIO_CAPA_ESCONDIDA, activation='sigmoid'), # 1era capa escondida\n",
    "    tf.keras.layers.Dense(TAMANIO_CAPA_ESCONDIDA, activation='sigmoid'), # 2nda capa escondida\n",
    "    tf.keras.layers.Dense(tamanio_salida, activation='softmax') # capa salida\n",
    "])\n",
    "\n",
    "# Crear el optimizador con una mayor tasa de aprendizaje\n",
    "optimizador = Adam(learning_rate=TASA_APRENDIZAJE)\n",
    "\n",
    "# Compilamos el modelo utilizando la tasa de aprendizaje por defecto (0.001)\n",
    "modelo.compile(optimizer=optimizador, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Crear variable para almacenar los resultados\n",
    "results = []\n",
    "\n",
    "# Entrenar el modelo\n",
    "print(f\"Entrenando modelo...\")\n",
    "start = time.time()\n",
    "historia = modelo.fit(datos_entreno, epochs=NUMERO_EPOCAS, validation_data=datos_validacion, verbose=1)\n",
    "end = time.time()\n",
    "tiempo_entrenamiento = end - start\n",
    "print(\"Listo!\")\n",
    "\n",
    "# Obtener la pérdida\n",
    "print(\"Evaluando modelo...\")\n",
    "perdida_prueba, precision_prueba = modelo.evaluate(datos_prueba)\n",
    "\n",
    "# Obtener la precisión de prueba final\n",
    "precision_entrenamiento = historia.history['accuracy'][-1]\n",
    "\n",
    "# Obtener la precisión de validación final\n",
    "precision_validacion = historia.history['val_accuracy'][-1]\n",
    "\n",
    "# Guardar los resultados\n",
    "results.append({\n",
    "    \"Precisión de entrenamiento\": \"{:.2f}%\".format(precision_entrenamiento * 100),\n",
    "    \"Precisión de prueba\": \"{:.2f}%\".format(precision_prueba * 100),\n",
    "    \"Precisión de validación\": \"{:.2f}%\".format(precision_validacion * 100),\n",
    "    \"Tiempo de entrenamiento (s)\": \"{:.2f}\".format(tiempo_entrenamiento)\n",
    "})\n",
    "print(\"Listo!\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precisión de entrenamiento</th>\n",
       "      <th>Precisión de prueba</th>\n",
       "      <th>Precisión de validación</th>\n",
       "      <th>Tiempo de entrenamiento (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>98.69%</td>\n",
       "      <td>97.25%</td>\n",
       "      <td>97.48%</td>\n",
       "      <td>21.89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Precisión de entrenamiento Precisión de prueba Precisión de validación  \\\n",
       "0                     98.69%              97.25%                  97.48%   \n",
       "\n",
       "  Tiempo de entrenamiento (s)  \n",
       "0                       21.89  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mostrar resultados como dataframe\n",
    "df = pd.DataFrame(results)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo con TAMANIO_TANDA=600, TAMANIO_CAPA_ESCONDIDA=512, TASA_APRENDIZAJE=0.001, NUMERO_EPOCAS=20...\n",
      "Epoch 1/20\n",
      "84/84 [==============================] - 2s 14ms/step - loss: 1.0963 - accuracy: 0.7021 - val_loss: 0.3982 - val_accuracy: 0.8930\n",
      "Epoch 2/20\n",
      "84/84 [==============================] - 1s 12ms/step - loss: 0.3555 - accuracy: 0.8994 - val_loss: 0.2810 - val_accuracy: 0.9180\n",
      "Epoch 3/20\n",
      "84/84 [==============================] - 1s 12ms/step - loss: 0.2828 - accuracy: 0.9174 - val_loss: 0.2409 - val_accuracy: 0.9299\n",
      "Epoch 4/20\n",
      "84/84 [==============================] - 1s 12ms/step - loss: 0.2466 - accuracy: 0.9277 - val_loss: 0.2209 - val_accuracy: 0.9359\n",
      "Epoch 5/20\n",
      "84/84 [==============================] - 1s 12ms/step - loss: 0.2193 - accuracy: 0.9347 - val_loss: 0.2013 - val_accuracy: 0.9426\n",
      "Epoch 6/20\n",
      "84/84 [==============================] - 1s 12ms/step - loss: 0.1974 - accuracy: 0.9416 - val_loss: 0.1806 - val_accuracy: 0.9488\n",
      "Epoch 7/20\n",
      "84/84 [==============================] - 1s 12ms/step - loss: 0.1774 - accuracy: 0.9470 - val_loss: 0.1663 - val_accuracy: 0.9535\n",
      "Epoch 8/20\n",
      "84/84 [==============================] - 1s 12ms/step - loss: 0.1589 - accuracy: 0.9532 - val_loss: 0.1609 - val_accuracy: 0.9546\n",
      "Epoch 9/20\n",
      "84/84 [==============================] - 1s 12ms/step - loss: 0.1436 - accuracy: 0.9580 - val_loss: 0.1421 - val_accuracy: 0.9600\n",
      "Epoch 10/20\n",
      "84/84 [==============================] - 1s 12ms/step - loss: 0.1298 - accuracy: 0.9621 - val_loss: 0.1394 - val_accuracy: 0.9612\n",
      "Epoch 11/20\n",
      "84/84 [==============================] - 1s 12ms/step - loss: 0.1186 - accuracy: 0.9646 - val_loss: 0.1279 - val_accuracy: 0.9638\n",
      "Epoch 12/20\n",
      "84/84 [==============================] - 1s 12ms/step - loss: 0.1069 - accuracy: 0.9687 - val_loss: 0.1207 - val_accuracy: 0.9652\n",
      "Epoch 13/20\n",
      "84/84 [==============================] - 1s 12ms/step - loss: 0.0956 - accuracy: 0.9724 - val_loss: 0.1148 - val_accuracy: 0.9665\n",
      "Epoch 14/20\n",
      "84/84 [==============================] - 1s 12ms/step - loss: 0.0879 - accuracy: 0.9743 - val_loss: 0.1076 - val_accuracy: 0.9688\n",
      "Epoch 15/20\n",
      "84/84 [==============================] - 1s 12ms/step - loss: 0.0795 - accuracy: 0.9769 - val_loss: 0.1025 - val_accuracy: 0.9702\n",
      "Epoch 16/20\n",
      "84/84 [==============================] - 1s 12ms/step - loss: 0.0711 - accuracy: 0.9794 - val_loss: 0.0975 - val_accuracy: 0.9728\n",
      "Epoch 17/20\n",
      "84/84 [==============================] - 1s 12ms/step - loss: 0.0655 - accuracy: 0.9812 - val_loss: 0.0930 - val_accuracy: 0.9734\n",
      "Epoch 18/20\n",
      "84/84 [==============================] - 1s 12ms/step - loss: 0.0598 - accuracy: 0.9825 - val_loss: 0.0911 - val_accuracy: 0.9745\n",
      "Epoch 19/20\n",
      "84/84 [==============================] - 1s 12ms/step - loss: 0.0528 - accuracy: 0.9853 - val_loss: 0.0879 - val_accuracy: 0.9734\n",
      "Epoch 20/20\n",
      "84/84 [==============================] - 1s 12ms/step - loss: 0.0477 - accuracy: 0.9869 - val_loss: 0.0894 - val_accuracy: 0.9742\n",
      "Listo!\n",
      "Precisión de validación actual: 97.42%\n",
      "Tiempo de entrenamiento: 22.73 segundos\n",
      "Entrenando modelo con TAMANIO_TANDA=600, TAMANIO_CAPA_ESCONDIDA=640, TASA_APRENDIZAJE=0.0009000000000000001, NUMERO_EPOCAS=25...\n",
      "Epoch 1/25\n",
      "84/84 [==============================] - 2s 18ms/step - loss: 1.0939 - accuracy: 0.6941 - val_loss: 0.3897 - val_accuracy: 0.8948\n",
      "Epoch 2/25\n",
      "84/84 [==============================] - 1s 15ms/step - loss: 0.3522 - accuracy: 0.9008 - val_loss: 0.2797 - val_accuracy: 0.9206\n",
      "Epoch 3/25\n",
      "84/84 [==============================] - 1s 15ms/step - loss: 0.2875 - accuracy: 0.9168 - val_loss: 0.2492 - val_accuracy: 0.9274\n",
      "Epoch 4/25\n",
      "84/84 [==============================] - 1s 15ms/step - loss: 0.2535 - accuracy: 0.9259 - val_loss: 0.2292 - val_accuracy: 0.9356\n",
      "Epoch 5/25\n",
      "84/84 [==============================] - 1s 15ms/step - loss: 0.2283 - accuracy: 0.9326 - val_loss: 0.2039 - val_accuracy: 0.9414\n",
      "Epoch 6/25\n",
      "84/84 [==============================] - 1s 16ms/step - loss: 0.2050 - accuracy: 0.9400 - val_loss: 0.1853 - val_accuracy: 0.9484\n",
      "Epoch 7/25\n",
      "84/84 [==============================] - 1s 15ms/step - loss: 0.1837 - accuracy: 0.9461 - val_loss: 0.1707 - val_accuracy: 0.9520\n",
      "Epoch 8/25\n",
      "84/84 [==============================] - 1s 15ms/step - loss: 0.1654 - accuracy: 0.9510 - val_loss: 0.1596 - val_accuracy: 0.9547\n",
      "Epoch 9/25\n",
      "84/84 [==============================] - 1s 15ms/step - loss: 0.1503 - accuracy: 0.9553 - val_loss: 0.1559 - val_accuracy: 0.9547\n",
      "Epoch 10/25\n",
      "84/84 [==============================] - 1s 15ms/step - loss: 0.1373 - accuracy: 0.9592 - val_loss: 0.1410 - val_accuracy: 0.9589\n",
      "Epoch 11/25\n",
      "84/84 [==============================] - 1s 15ms/step - loss: 0.1245 - accuracy: 0.9628 - val_loss: 0.1339 - val_accuracy: 0.9608\n",
      "Epoch 12/25\n",
      "84/84 [==============================] - 1s 15ms/step - loss: 0.1151 - accuracy: 0.9662 - val_loss: 0.1233 - val_accuracy: 0.9647\n",
      "Epoch 13/25\n",
      "84/84 [==============================] - 1s 15ms/step - loss: 0.1040 - accuracy: 0.9697 - val_loss: 0.1167 - val_accuracy: 0.9670\n",
      "Epoch 14/25\n",
      "84/84 [==============================] - 1s 15ms/step - loss: 0.0957 - accuracy: 0.9715 - val_loss: 0.1186 - val_accuracy: 0.9661\n",
      "Epoch 15/25\n",
      "84/84 [==============================] - 1s 15ms/step - loss: 0.0869 - accuracy: 0.9744 - val_loss: 0.1081 - val_accuracy: 0.9689\n",
      "Epoch 16/25\n",
      "84/84 [==============================] - 1s 15ms/step - loss: 0.0778 - accuracy: 0.9774 - val_loss: 0.1013 - val_accuracy: 0.9709\n",
      "Epoch 17/25\n",
      "84/84 [==============================] - 1s 16ms/step - loss: 0.0734 - accuracy: 0.9780 - val_loss: 0.0989 - val_accuracy: 0.9711\n",
      "Epoch 18/25\n",
      "84/84 [==============================] - 1s 16ms/step - loss: 0.0655 - accuracy: 0.9808 - val_loss: 0.0947 - val_accuracy: 0.9726\n",
      "Epoch 19/25\n",
      "84/84 [==============================] - 1s 15ms/step - loss: 0.0586 - accuracy: 0.9834 - val_loss: 0.0948 - val_accuracy: 0.9725\n",
      "Epoch 20/25\n",
      "84/84 [==============================] - 1s 15ms/step - loss: 0.0542 - accuracy: 0.9841 - val_loss: 0.0881 - val_accuracy: 0.9745\n",
      "Epoch 21/25\n",
      "84/84 [==============================] - 1s 15ms/step - loss: 0.0487 - accuracy: 0.9863 - val_loss: 0.0870 - val_accuracy: 0.9741\n",
      "Epoch 22/25\n",
      "84/84 [==============================] - 1s 16ms/step - loss: 0.0444 - accuracy: 0.9874 - val_loss: 0.0834 - val_accuracy: 0.9755\n",
      "Epoch 23/25\n",
      "84/84 [==============================] - 1s 15ms/step - loss: 0.0406 - accuracy: 0.9885 - val_loss: 0.0841 - val_accuracy: 0.9759\n",
      "Epoch 24/25\n",
      "84/84 [==============================] - 1s 15ms/step - loss: 0.0372 - accuracy: 0.9897 - val_loss: 0.0807 - val_accuracy: 0.9757\n",
      "Epoch 25/25\n",
      "84/84 [==============================] - 1s 15ms/step - loss: 0.0325 - accuracy: 0.9915 - val_loss: 0.0812 - val_accuracy: 0.9762\n",
      "Listo!\n",
      "Precisión de validación actual: 97.62%\n",
      "Tiempo de entrenamiento: 34.58 segundos\n",
      "Entrenando modelo con TAMANIO_TANDA=600, TAMANIO_CAPA_ESCONDIDA=768, TASA_APRENDIZAJE=0.0008100000000000001, NUMERO_EPOCAS=30...\n",
      "Epoch 1/30\n",
      "84/84 [==============================] - 2s 19ms/step - loss: 1.1784 - accuracy: 0.6676 - val_loss: 0.4158 - val_accuracy: 0.8946\n",
      "Epoch 2/30\n",
      "84/84 [==============================] - 2s 17ms/step - loss: 0.3671 - accuracy: 0.8980 - val_loss: 0.2880 - val_accuracy: 0.9175\n",
      "Epoch 3/30\n",
      "84/84 [==============================] - 1s 17ms/step - loss: 0.2927 - accuracy: 0.9145 - val_loss: 0.2503 - val_accuracy: 0.9279\n",
      "Epoch 4/30\n",
      "84/84 [==============================] - 1s 17ms/step - loss: 0.2612 - accuracy: 0.9224 - val_loss: 0.2287 - val_accuracy: 0.9342\n",
      "Epoch 5/30\n",
      "84/84 [==============================] - 1s 17ms/step - loss: 0.2372 - accuracy: 0.9299 - val_loss: 0.2118 - val_accuracy: 0.9417\n",
      "Epoch 6/30\n",
      "84/84 [==============================] - 2s 17ms/step - loss: 0.2119 - accuracy: 0.9378 - val_loss: 0.1945 - val_accuracy: 0.9468\n",
      "Epoch 7/30\n",
      "84/84 [==============================] - 1s 17ms/step - loss: 0.1933 - accuracy: 0.9430 - val_loss: 0.1830 - val_accuracy: 0.9481\n",
      "Epoch 8/30\n",
      "84/84 [==============================] - 2s 17ms/step - loss: 0.1767 - accuracy: 0.9477 - val_loss: 0.1656 - val_accuracy: 0.9534\n",
      "Epoch 9/30\n",
      "84/84 [==============================] - 2s 18ms/step - loss: 0.1605 - accuracy: 0.9525 - val_loss: 0.1634 - val_accuracy: 0.9536\n",
      "Epoch 10/30\n",
      "84/84 [==============================] - 2s 17ms/step - loss: 0.1474 - accuracy: 0.9568 - val_loss: 0.1474 - val_accuracy: 0.9593\n",
      "Epoch 11/30\n",
      "84/84 [==============================] - 1s 17ms/step - loss: 0.1351 - accuracy: 0.9602 - val_loss: 0.1356 - val_accuracy: 0.9623\n",
      "Epoch 12/30\n",
      "84/84 [==============================] - 1s 17ms/step - loss: 0.1233 - accuracy: 0.9639 - val_loss: 0.1351 - val_accuracy: 0.9618\n",
      "Epoch 13/30\n",
      "84/84 [==============================] - 2s 18ms/step - loss: 0.1134 - accuracy: 0.9666 - val_loss: 0.1223 - val_accuracy: 0.9643\n",
      "Epoch 14/30\n",
      "84/84 [==============================] - 2s 22ms/step - loss: 0.1039 - accuracy: 0.9698 - val_loss: 0.1161 - val_accuracy: 0.9669\n",
      "Epoch 15/30\n",
      "84/84 [==============================] - 1s 17ms/step - loss: 0.0943 - accuracy: 0.9724 - val_loss: 0.1113 - val_accuracy: 0.9688\n",
      "Epoch 16/30\n",
      "84/84 [==============================] - 2s 17ms/step - loss: 0.0880 - accuracy: 0.9750 - val_loss: 0.1081 - val_accuracy: 0.9688\n",
      "Epoch 17/30\n",
      "84/84 [==============================] - 2s 17ms/step - loss: 0.0793 - accuracy: 0.9765 - val_loss: 0.1018 - val_accuracy: 0.9694\n",
      "Epoch 18/30\n",
      "84/84 [==============================] - 2s 18ms/step - loss: 0.0722 - accuracy: 0.9787 - val_loss: 0.0966 - val_accuracy: 0.9725\n",
      "Epoch 19/30\n",
      "84/84 [==============================] - 2s 17ms/step - loss: 0.0666 - accuracy: 0.9805 - val_loss: 0.0953 - val_accuracy: 0.9721\n",
      "Epoch 20/30\n",
      "84/84 [==============================] - 2s 17ms/step - loss: 0.0611 - accuracy: 0.9823 - val_loss: 0.0915 - val_accuracy: 0.9734\n",
      "Epoch 21/30\n",
      "84/84 [==============================] - 2s 17ms/step - loss: 0.0550 - accuracy: 0.9842 - val_loss: 0.0897 - val_accuracy: 0.9721\n",
      "Epoch 22/30\n",
      "84/84 [==============================] - 2s 17ms/step - loss: 0.0503 - accuracy: 0.9856 - val_loss: 0.0872 - val_accuracy: 0.9737\n",
      "Epoch 23/30\n",
      "84/84 [==============================] - 2s 18ms/step - loss: 0.0472 - accuracy: 0.9864 - val_loss: 0.0884 - val_accuracy: 0.9727\n",
      "Epoch 24/30\n",
      "84/84 [==============================] - 1s 17ms/step - loss: 0.0415 - accuracy: 0.9886 - val_loss: 0.0846 - val_accuracy: 0.9740\n",
      "Epoch 25/30\n",
      "84/84 [==============================] - 2s 17ms/step - loss: 0.0394 - accuracy: 0.9895 - val_loss: 0.0837 - val_accuracy: 0.9763\n",
      "Epoch 26/30\n",
      "84/84 [==============================] - 2s 18ms/step - loss: 0.0359 - accuracy: 0.9896 - val_loss: 0.0818 - val_accuracy: 0.9749\n",
      "Epoch 27/30\n",
      "84/84 [==============================] - 2s 17ms/step - loss: 0.0325 - accuracy: 0.9911 - val_loss: 0.0859 - val_accuracy: 0.9743\n",
      "Epoch 28/30\n",
      "84/84 [==============================] - 2s 19ms/step - loss: 0.0287 - accuracy: 0.9928 - val_loss: 0.0799 - val_accuracy: 0.9765\n",
      "Epoch 29/30\n",
      "84/84 [==============================] - 2s 18ms/step - loss: 0.0257 - accuracy: 0.9939 - val_loss: 0.0779 - val_accuracy: 0.9774\n",
      "Epoch 30/30\n",
      "84/84 [==============================] - 2s 18ms/step - loss: 0.0230 - accuracy: 0.9947 - val_loss: 0.0765 - val_accuracy: 0.9785\n",
      "Listo!\n",
      "Precisión de validación actual: 97.85%\n",
      "Tiempo de entrenamiento: 46.99 segundos\n",
      "Entrenando modelo con TAMANIO_TANDA=600, TAMANIO_CAPA_ESCONDIDA=896, TASA_APRENDIZAJE=0.000729, NUMERO_EPOCAS=35...\n",
      "Epoch 1/35\n",
      "84/84 [==============================] - 2s 22ms/step - loss: 1.1163 - accuracy: 0.6870 - val_loss: 0.3944 - val_accuracy: 0.8955\n",
      "Epoch 2/35\n",
      "84/84 [==============================] - 2s 20ms/step - loss: 0.3607 - accuracy: 0.8985 - val_loss: 0.2874 - val_accuracy: 0.9202\n",
      "Epoch 3/35\n",
      "84/84 [==============================] - 2s 20ms/step - loss: 0.2955 - accuracy: 0.9142 - val_loss: 0.2564 - val_accuracy: 0.9270\n",
      "Epoch 4/35\n",
      "84/84 [==============================] - 2s 20ms/step - loss: 0.2655 - accuracy: 0.9227 - val_loss: 0.2347 - val_accuracy: 0.9332\n",
      "Epoch 5/35\n",
      "84/84 [==============================] - 2s 20ms/step - loss: 0.2432 - accuracy: 0.9288 - val_loss: 0.2154 - val_accuracy: 0.9386\n",
      "Epoch 6/35\n",
      "84/84 [==============================] - 2s 20ms/step - loss: 0.2211 - accuracy: 0.9341 - val_loss: 0.2073 - val_accuracy: 0.9404\n",
      "Epoch 7/35\n",
      "84/84 [==============================] - 2s 20ms/step - loss: 0.2026 - accuracy: 0.9409 - val_loss: 0.1810 - val_accuracy: 0.9509\n",
      "Epoch 8/35\n",
      "84/84 [==============================] - 2s 21ms/step - loss: 0.1857 - accuracy: 0.9456 - val_loss: 0.1740 - val_accuracy: 0.9522\n",
      "Epoch 9/35\n",
      "84/84 [==============================] - 2s 20ms/step - loss: 0.1696 - accuracy: 0.9510 - val_loss: 0.1619 - val_accuracy: 0.9531\n",
      "Epoch 10/35\n",
      "84/84 [==============================] - 2s 20ms/step - loss: 0.1568 - accuracy: 0.9540 - val_loss: 0.1533 - val_accuracy: 0.9560\n",
      "Epoch 11/35\n",
      "84/84 [==============================] - 2s 20ms/step - loss: 0.1431 - accuracy: 0.9579 - val_loss: 0.1418 - val_accuracy: 0.9592\n",
      "Epoch 12/35\n",
      "84/84 [==============================] - 2s 19ms/step - loss: 0.1315 - accuracy: 0.9610 - val_loss: 0.1373 - val_accuracy: 0.9618\n",
      "Epoch 13/35\n",
      "84/84 [==============================] - 2s 19ms/step - loss: 0.1212 - accuracy: 0.9645 - val_loss: 0.1294 - val_accuracy: 0.9636\n",
      "Epoch 14/35\n",
      "84/84 [==============================] - 2s 20ms/step - loss: 0.1118 - accuracy: 0.9675 - val_loss: 0.1308 - val_accuracy: 0.9636\n",
      "Epoch 15/35\n",
      "84/84 [==============================] - 2s 19ms/step - loss: 0.1055 - accuracy: 0.9694 - val_loss: 0.1164 - val_accuracy: 0.9671\n",
      "Epoch 16/35\n",
      "84/84 [==============================] - 2s 20ms/step - loss: 0.0954 - accuracy: 0.9722 - val_loss: 0.1129 - val_accuracy: 0.9671\n",
      "Epoch 17/35\n",
      "84/84 [==============================] - 2s 20ms/step - loss: 0.0877 - accuracy: 0.9741 - val_loss: 0.1075 - val_accuracy: 0.9704\n",
      "Epoch 18/35\n",
      "84/84 [==============================] - 2s 20ms/step - loss: 0.0809 - accuracy: 0.9766 - val_loss: 0.1036 - val_accuracy: 0.9693\n",
      "Epoch 19/35\n",
      "84/84 [==============================] - 2s 21ms/step - loss: 0.0742 - accuracy: 0.9781 - val_loss: 0.0985 - val_accuracy: 0.9711\n",
      "Epoch 20/35\n",
      "84/84 [==============================] - 2s 23ms/step - loss: 0.0692 - accuracy: 0.9799 - val_loss: 0.0994 - val_accuracy: 0.9723\n",
      "Epoch 21/35\n",
      "84/84 [==============================] - 2s 26ms/step - loss: 0.0635 - accuracy: 0.9817 - val_loss: 0.0945 - val_accuracy: 0.9728\n",
      "Epoch 22/35\n",
      "84/84 [==============================] - 2s 21ms/step - loss: 0.0597 - accuracy: 0.9832 - val_loss: 0.0961 - val_accuracy: 0.9723\n",
      "Epoch 23/35\n",
      "84/84 [==============================] - 2s 21ms/step - loss: 0.0538 - accuracy: 0.9848 - val_loss: 0.0876 - val_accuracy: 0.9738\n",
      "Epoch 24/35\n",
      "84/84 [==============================] - 2s 20ms/step - loss: 0.0494 - accuracy: 0.9857 - val_loss: 0.0902 - val_accuracy: 0.9734\n",
      "Epoch 25/35\n",
      "84/84 [==============================] - 2s 20ms/step - loss: 0.0452 - accuracy: 0.9868 - val_loss: 0.0830 - val_accuracy: 0.9752\n",
      "Epoch 26/35\n",
      "84/84 [==============================] - 2s 21ms/step - loss: 0.0411 - accuracy: 0.9885 - val_loss: 0.0824 - val_accuracy: 0.9763\n",
      "Epoch 27/35\n",
      "84/84 [==============================] - 2s 22ms/step - loss: 0.0384 - accuracy: 0.9893 - val_loss: 0.0843 - val_accuracy: 0.9742\n",
      "Epoch 28/35\n",
      "84/84 [==============================] - 2s 24ms/step - loss: 0.0353 - accuracy: 0.9905 - val_loss: 0.0811 - val_accuracy: 0.9762\n",
      "Epoch 29/35\n",
      "84/84 [==============================] - 2s 20ms/step - loss: 0.0311 - accuracy: 0.9920 - val_loss: 0.0791 - val_accuracy: 0.9764\n",
      "Epoch 30/35\n",
      "84/84 [==============================] - 2s 20ms/step - loss: 0.0279 - accuracy: 0.9927 - val_loss: 0.0794 - val_accuracy: 0.9757\n",
      "Epoch 31/35\n",
      "84/84 [==============================] - 2s 20ms/step - loss: 0.0261 - accuracy: 0.9935 - val_loss: 0.0774 - val_accuracy: 0.9766\n",
      "Epoch 32/35\n",
      "84/84 [==============================] - 2s 20ms/step - loss: 0.0251 - accuracy: 0.9932 - val_loss: 0.0797 - val_accuracy: 0.9768\n",
      "Epoch 33/35\n",
      "84/84 [==============================] - 2s 20ms/step - loss: 0.0237 - accuracy: 0.9937 - val_loss: 0.0755 - val_accuracy: 0.9781\n",
      "Epoch 34/35\n",
      "84/84 [==============================] - 2s 21ms/step - loss: 0.0194 - accuracy: 0.9956 - val_loss: 0.0763 - val_accuracy: 0.9769\n",
      "Epoch 35/35\n",
      "84/84 [==============================] - 2s 20ms/step - loss: 0.0195 - accuracy: 0.9954 - val_loss: 0.0784 - val_accuracy: 0.9785\n",
      "Listo!\n",
      "Precisión de validación actual: 97.85%\n",
      "Tiempo de entrenamiento: 63.71 segundos\n",
      "Entrenando modelo con TAMANIO_TANDA=600, TAMANIO_CAPA_ESCONDIDA=1024, TASA_APRENDIZAJE=0.0006561000000000001, NUMERO_EPOCAS=40...\n",
      "Epoch 1/40\n",
      "84/84 [==============================] - 3s 26ms/step - loss: 1.1542 - accuracy: 0.6804 - val_loss: 0.4141 - val_accuracy: 0.8909\n",
      "Epoch 2/40\n",
      "84/84 [==============================] - 2s 24ms/step - loss: 0.3706 - accuracy: 0.8960 - val_loss: 0.3068 - val_accuracy: 0.9104\n",
      "Epoch 3/40\n",
      "84/84 [==============================] - 2s 24ms/step - loss: 0.3006 - accuracy: 0.9129 - val_loss: 0.2603 - val_accuracy: 0.9225\n",
      "Epoch 4/40\n",
      "84/84 [==============================] - 2s 24ms/step - loss: 0.2717 - accuracy: 0.9200 - val_loss: 0.2430 - val_accuracy: 0.9307\n",
      "Epoch 5/40\n",
      "84/84 [==============================] - 2s 23ms/step - loss: 0.2516 - accuracy: 0.9259 - val_loss: 0.2260 - val_accuracy: 0.9343\n",
      "Epoch 6/40\n",
      "84/84 [==============================] - 2s 24ms/step - loss: 0.2307 - accuracy: 0.9321 - val_loss: 0.2145 - val_accuracy: 0.9389\n",
      "Epoch 7/40\n",
      "84/84 [==============================] - 2s 24ms/step - loss: 0.2131 - accuracy: 0.9382 - val_loss: 0.1986 - val_accuracy: 0.9432\n",
      "Epoch 8/40\n",
      "84/84 [==============================] - 3s 30ms/step - loss: 0.1965 - accuracy: 0.9429 - val_loss: 0.1859 - val_accuracy: 0.9486\n",
      "Epoch 9/40\n",
      "84/84 [==============================] - 2s 27ms/step - loss: 0.1812 - accuracy: 0.9469 - val_loss: 0.1752 - val_accuracy: 0.9521\n",
      "Epoch 10/40\n",
      "84/84 [==============================] - 2s 25ms/step - loss: 0.1676 - accuracy: 0.9508 - val_loss: 0.1624 - val_accuracy: 0.9522\n",
      "Epoch 11/40\n",
      "84/84 [==============================] - 2s 24ms/step - loss: 0.1545 - accuracy: 0.9538 - val_loss: 0.1515 - val_accuracy: 0.9578\n",
      "Epoch 12/40\n",
      "84/84 [==============================] - 2s 24ms/step - loss: 0.1434 - accuracy: 0.9579 - val_loss: 0.1503 - val_accuracy: 0.9579\n",
      "Epoch 13/40\n",
      "84/84 [==============================] - 2s 23ms/step - loss: 0.1338 - accuracy: 0.9599 - val_loss: 0.1380 - val_accuracy: 0.9614\n",
      "Epoch 14/40\n",
      "84/84 [==============================] - 2s 23ms/step - loss: 0.1210 - accuracy: 0.9646 - val_loss: 0.1337 - val_accuracy: 0.9625\n",
      "Epoch 15/40\n",
      "84/84 [==============================] - 2s 24ms/step - loss: 0.1149 - accuracy: 0.9655 - val_loss: 0.1264 - val_accuracy: 0.9638\n",
      "Epoch 16/40\n",
      "84/84 [==============================] - 2s 24ms/step - loss: 0.1062 - accuracy: 0.9691 - val_loss: 0.1190 - val_accuracy: 0.9664\n",
      "Epoch 17/40\n",
      "84/84 [==============================] - 2s 24ms/step - loss: 0.0982 - accuracy: 0.9712 - val_loss: 0.1149 - val_accuracy: 0.9677\n",
      "Epoch 18/40\n",
      "84/84 [==============================] - 2s 23ms/step - loss: 0.0923 - accuracy: 0.9734 - val_loss: 0.1113 - val_accuracy: 0.9681\n",
      "Epoch 19/40\n",
      "84/84 [==============================] - 2s 24ms/step - loss: 0.0850 - accuracy: 0.9751 - val_loss: 0.1074 - val_accuracy: 0.9672\n",
      "Epoch 20/40\n",
      "84/84 [==============================] - 2s 23ms/step - loss: 0.0780 - accuracy: 0.9770 - val_loss: 0.1074 - val_accuracy: 0.9677\n",
      "Epoch 21/40\n",
      "84/84 [==============================] - 2s 25ms/step - loss: 0.0734 - accuracy: 0.9784 - val_loss: 0.1008 - val_accuracy: 0.9708\n",
      "Epoch 22/40\n",
      "84/84 [==============================] - 2s 25ms/step - loss: 0.0663 - accuracy: 0.9805 - val_loss: 0.1010 - val_accuracy: 0.9711\n",
      "Epoch 23/40\n",
      "84/84 [==============================] - 2s 24ms/step - loss: 0.0611 - accuracy: 0.9825 - val_loss: 0.0935 - val_accuracy: 0.9723\n",
      "Epoch 24/40\n",
      "84/84 [==============================] - 2s 23ms/step - loss: 0.0572 - accuracy: 0.9837 - val_loss: 0.0916 - val_accuracy: 0.9732\n",
      "Epoch 25/40\n",
      "84/84 [==============================] - 2s 24ms/step - loss: 0.0537 - accuracy: 0.9847 - val_loss: 0.0907 - val_accuracy: 0.9741\n",
      "Epoch 26/40\n",
      "84/84 [==============================] - 2s 23ms/step - loss: 0.0494 - accuracy: 0.9859 - val_loss: 0.0860 - val_accuracy: 0.9750\n",
      "Epoch 27/40\n",
      "84/84 [==============================] - 2s 24ms/step - loss: 0.0482 - accuracy: 0.9859 - val_loss: 0.0854 - val_accuracy: 0.9733\n",
      "Epoch 28/40\n",
      "84/84 [==============================] - 2s 24ms/step - loss: 0.0416 - accuracy: 0.9880 - val_loss: 0.0854 - val_accuracy: 0.9749\n",
      "Epoch 29/40\n",
      "84/84 [==============================] - 2s 25ms/step - loss: 0.0384 - accuracy: 0.9895 - val_loss: 0.0829 - val_accuracy: 0.9751\n",
      "Epoch 30/40\n",
      "84/84 [==============================] - 2s 24ms/step - loss: 0.0345 - accuracy: 0.9905 - val_loss: 0.0807 - val_accuracy: 0.9762\n",
      "Epoch 31/40\n",
      "84/84 [==============================] - 2s 23ms/step - loss: 0.0321 - accuracy: 0.9918 - val_loss: 0.0800 - val_accuracy: 0.9762\n",
      "Epoch 32/40\n",
      "84/84 [==============================] - 2s 24ms/step - loss: 0.0288 - accuracy: 0.9930 - val_loss: 0.0854 - val_accuracy: 0.9759\n",
      "Epoch 33/40\n",
      "84/84 [==============================] - 2s 24ms/step - loss: 0.0276 - accuracy: 0.9929 - val_loss: 0.0816 - val_accuracy: 0.9764\n",
      "Epoch 34/40\n",
      "84/84 [==============================] - 2s 23ms/step - loss: 0.0248 - accuracy: 0.9937 - val_loss: 0.0835 - val_accuracy: 0.9757\n",
      "Epoch 35/40\n",
      "84/84 [==============================] - 2s 24ms/step - loss: 0.0224 - accuracy: 0.9947 - val_loss: 0.0788 - val_accuracy: 0.9782\n",
      "Epoch 36/40\n",
      "84/84 [==============================] - 2s 23ms/step - loss: 0.0205 - accuracy: 0.9949 - val_loss: 0.0816 - val_accuracy: 0.9780\n",
      "Epoch 37/40\n",
      "84/84 [==============================] - 2s 23ms/step - loss: 0.0186 - accuracy: 0.9957 - val_loss: 0.0819 - val_accuracy: 0.9783\n",
      "Epoch 38/40\n",
      "84/84 [==============================] - 2s 23ms/step - loss: 0.0183 - accuracy: 0.9958 - val_loss: 0.0812 - val_accuracy: 0.9776\n",
      "Epoch 39/40\n",
      "84/84 [==============================] - 2s 23ms/step - loss: 0.0157 - accuracy: 0.9965 - val_loss: 0.0771 - val_accuracy: 0.9791\n",
      "Epoch 40/40\n",
      "84/84 [==============================] - 2s 24ms/step - loss: 0.0137 - accuracy: 0.9975 - val_loss: 0.0804 - val_accuracy: 0.9793\n",
      "Listo!\n",
      "Precisión de validación actual: 97.93%\n",
      "Tiempo de entrenamiento: 84.17 segundos\n",
      "Entrenando modelo con TAMANIO_TANDA=600, TAMANIO_CAPA_ESCONDIDA=1152, TASA_APRENDIZAJE=0.00059049, NUMERO_EPOCAS=45...\n",
      "Epoch 1/45\n",
      "84/84 [==============================] - 3s 28ms/step - loss: 1.1736 - accuracy: 0.6716 - val_loss: 0.4393 - val_accuracy: 0.8876\n",
      "Epoch 2/45\n",
      "84/84 [==============================] - 2s 25ms/step - loss: 0.3841 - accuracy: 0.8915 - val_loss: 0.3014 - val_accuracy: 0.9138\n",
      "Epoch 3/45\n",
      "84/84 [==============================] - 2s 24ms/step - loss: 0.3096 - accuracy: 0.9107 - val_loss: 0.2713 - val_accuracy: 0.9246\n",
      "Epoch 4/45\n",
      "84/84 [==============================] - 2s 23ms/step - loss: 0.2805 - accuracy: 0.9186 - val_loss: 0.2497 - val_accuracy: 0.9282\n",
      "Epoch 5/45\n",
      "84/84 [==============================] - 2s 24ms/step - loss: 0.2584 - accuracy: 0.9251 - val_loss: 0.2383 - val_accuracy: 0.9314\n",
      "Epoch 6/45\n",
      "84/84 [==============================] - 2s 25ms/step - loss: 0.2439 - accuracy: 0.9282 - val_loss: 0.2235 - val_accuracy: 0.9342\n",
      "Epoch 7/45\n",
      "84/84 [==============================] - 2s 24ms/step - loss: 0.2259 - accuracy: 0.9329 - val_loss: 0.2079 - val_accuracy: 0.9424\n",
      "Epoch 8/45\n",
      "84/84 [==============================] - 2s 24ms/step - loss: 0.2101 - accuracy: 0.9385 - val_loss: 0.1944 - val_accuracy: 0.9457\n",
      "Epoch 9/45\n",
      "84/84 [==============================] - 3s 33ms/step - loss: 0.1925 - accuracy: 0.9435 - val_loss: 0.1830 - val_accuracy: 0.9489\n",
      "Epoch 10/45\n",
      "84/84 [==============================] - 2s 28ms/step - loss: 0.1786 - accuracy: 0.9479 - val_loss: 0.1759 - val_accuracy: 0.9504\n",
      "Epoch 11/45\n",
      "84/84 [==============================] - 2s 27ms/step - loss: 0.1675 - accuracy: 0.9512 - val_loss: 0.1655 - val_accuracy: 0.9531\n",
      "Epoch 12/45\n",
      "84/84 [==============================] - 2s 26ms/step - loss: 0.1542 - accuracy: 0.9545 - val_loss: 0.1606 - val_accuracy: 0.9552\n",
      "Epoch 13/45\n",
      "84/84 [==============================] - 2s 28ms/step - loss: 0.1442 - accuracy: 0.9578 - val_loss: 0.1458 - val_accuracy: 0.9592\n",
      "Epoch 14/45\n",
      "84/84 [==============================] - 2s 25ms/step - loss: 0.1325 - accuracy: 0.9615 - val_loss: 0.1405 - val_accuracy: 0.9614\n",
      "Epoch 15/45\n",
      "84/84 [==============================] - 2s 28ms/step - loss: 0.1235 - accuracy: 0.9631 - val_loss: 0.1391 - val_accuracy: 0.9592\n",
      "Epoch 16/45\n",
      "84/84 [==============================] - 2s 25ms/step - loss: 0.1172 - accuracy: 0.9654 - val_loss: 0.1296 - val_accuracy: 0.9632\n",
      "Epoch 17/45\n",
      "84/84 [==============================] - 2s 25ms/step - loss: 0.1076 - accuracy: 0.9682 - val_loss: 0.1261 - val_accuracy: 0.9650\n",
      "Epoch 18/45\n",
      "84/84 [==============================] - 2s 24ms/step - loss: 0.1012 - accuracy: 0.9702 - val_loss: 0.1167 - val_accuracy: 0.9650\n",
      "Epoch 19/45\n",
      "84/84 [==============================] - 2s 24ms/step - loss: 0.0935 - accuracy: 0.9729 - val_loss: 0.1223 - val_accuracy: 0.9653\n",
      "Epoch 20/45\n",
      "84/84 [==============================] - 2s 23ms/step - loss: 0.0898 - accuracy: 0.9735 - val_loss: 0.1065 - val_accuracy: 0.9684\n",
      "Epoch 21/45\n",
      "84/84 [==============================] - 2s 23ms/step - loss: 0.0811 - accuracy: 0.9763 - val_loss: 0.1087 - val_accuracy: 0.9673\n",
      "Epoch 22/45\n",
      "84/84 [==============================] - 2s 23ms/step - loss: 0.0763 - accuracy: 0.9774 - val_loss: 0.1013 - val_accuracy: 0.9715\n",
      "Epoch 23/45\n",
      "84/84 [==============================] - 2s 24ms/step - loss: 0.0713 - accuracy: 0.9790 - val_loss: 0.0981 - val_accuracy: 0.9708\n",
      "Epoch 24/45\n",
      "84/84 [==============================] - 2s 23ms/step - loss: 0.0643 - accuracy: 0.9815 - val_loss: 0.0957 - val_accuracy: 0.9713\n",
      "Epoch 25/45\n",
      "84/84 [==============================] - 2s 23ms/step - loss: 0.0602 - accuracy: 0.9826 - val_loss: 0.0928 - val_accuracy: 0.9729\n",
      "Epoch 26/45\n",
      "84/84 [==============================] - 2s 24ms/step - loss: 0.0565 - accuracy: 0.9834 - val_loss: 0.0915 - val_accuracy: 0.9730\n",
      "Epoch 27/45\n",
      "84/84 [==============================] - 2s 26ms/step - loss: 0.0525 - accuracy: 0.9848 - val_loss: 0.0884 - val_accuracy: 0.9742\n",
      "Epoch 28/45\n",
      "84/84 [==============================] - 2s 26ms/step - loss: 0.0494 - accuracy: 0.9857 - val_loss: 0.0868 - val_accuracy: 0.9738\n",
      "Epoch 29/45\n",
      "84/84 [==============================] - 2s 23ms/step - loss: 0.0450 - accuracy: 0.9872 - val_loss: 0.0851 - val_accuracy: 0.9752\n",
      "Epoch 30/45\n",
      "84/84 [==============================] - 2s 24ms/step - loss: 0.0420 - accuracy: 0.9879 - val_loss: 0.0889 - val_accuracy: 0.9741\n",
      "Epoch 31/45\n",
      "84/84 [==============================] - 2s 24ms/step - loss: 0.0398 - accuracy: 0.9888 - val_loss: 0.0854 - val_accuracy: 0.9752\n",
      "Epoch 32/45\n",
      "84/84 [==============================] - 2s 24ms/step - loss: 0.0347 - accuracy: 0.9904 - val_loss: 0.0820 - val_accuracy: 0.9751\n",
      "Epoch 33/45\n",
      "84/84 [==============================] - 2s 23ms/step - loss: 0.0333 - accuracy: 0.9910 - val_loss: 0.0867 - val_accuracy: 0.9748\n",
      "Epoch 34/45\n",
      "84/84 [==============================] - 2s 23ms/step - loss: 0.0305 - accuracy: 0.9917 - val_loss: 0.0792 - val_accuracy: 0.9774\n",
      "Epoch 35/45\n",
      "84/84 [==============================] - 2s 23ms/step - loss: 0.0288 - accuracy: 0.9924 - val_loss: 0.0829 - val_accuracy: 0.9765\n",
      "Epoch 36/45\n",
      "84/84 [==============================] - 2s 24ms/step - loss: 0.0255 - accuracy: 0.9937 - val_loss: 0.0812 - val_accuracy: 0.9757\n",
      "Epoch 37/45\n",
      "84/84 [==============================] - 2s 25ms/step - loss: 0.0241 - accuracy: 0.9942 - val_loss: 0.0806 - val_accuracy: 0.9764\n",
      "Epoch 38/45\n",
      "84/84 [==============================] - 2s 24ms/step - loss: 0.0220 - accuracy: 0.9947 - val_loss: 0.0833 - val_accuracy: 0.9756\n",
      "Epoch 39/45\n",
      "84/84 [==============================] - 2s 23ms/step - loss: 0.0199 - accuracy: 0.9948 - val_loss: 0.0799 - val_accuracy: 0.9769\n",
      "Epoch 40/45\n",
      "84/84 [==============================] - 2s 23ms/step - loss: 0.0188 - accuracy: 0.9957 - val_loss: 0.0817 - val_accuracy: 0.9757\n",
      "Epoch 41/45\n",
      "84/84 [==============================] - 2s 23ms/step - loss: 0.0178 - accuracy: 0.9958 - val_loss: 0.0795 - val_accuracy: 0.9786\n",
      "Epoch 42/45\n",
      "84/84 [==============================] - 2s 23ms/step - loss: 0.0159 - accuracy: 0.9965 - val_loss: 0.0808 - val_accuracy: 0.9764\n",
      "Epoch 43/45\n",
      "84/84 [==============================] - 2s 25ms/step - loss: 0.0151 - accuracy: 0.9967 - val_loss: 0.0807 - val_accuracy: 0.9781\n",
      "Epoch 44/45\n",
      "84/84 [==============================] - 2s 27ms/step - loss: 0.0129 - accuracy: 0.9973 - val_loss: 0.0840 - val_accuracy: 0.9776\n",
      "Epoch 45/45\n",
      "84/84 [==============================] - 2s 25ms/step - loss: 0.0116 - accuracy: 0.9980 - val_loss: 0.0849 - val_accuracy: 0.9757\n",
      "Listo!\n",
      "Precisión de validación actual: 97.57%\n",
      "Tiempo de entrenamiento: 97.63 segundos\n",
      "Entrenando modelo con TAMANIO_TANDA=600, TAMANIO_CAPA_ESCONDIDA=1280, TASA_APRENDIZAJE=0.000531441, NUMERO_EPOCAS=50...\n",
      "Epoch 1/50\n",
      "84/84 [==============================] - 3s 32ms/step - loss: 1.2389 - accuracy: 0.6636 - val_loss: 0.4525 - val_accuracy: 0.8808\n",
      "Epoch 2/50\n",
      "84/84 [==============================] - 2s 29ms/step - loss: 0.3938 - accuracy: 0.8907 - val_loss: 0.3092 - val_accuracy: 0.9120\n",
      "Epoch 3/50\n",
      "84/84 [==============================] - 3s 30ms/step - loss: 0.3135 - accuracy: 0.9095 - val_loss: 0.2705 - val_accuracy: 0.9211\n",
      "Epoch 4/50\n",
      "84/84 [==============================] - 3s 31ms/step - loss: 0.2856 - accuracy: 0.9162 - val_loss: 0.2583 - val_accuracy: 0.9258\n",
      "Epoch 5/50\n",
      "84/84 [==============================] - 2s 28ms/step - loss: 0.2663 - accuracy: 0.9220 - val_loss: 0.2426 - val_accuracy: 0.9283\n",
      "Epoch 6/50\n",
      "84/84 [==============================] - 3s 32ms/step - loss: 0.2479 - accuracy: 0.9274 - val_loss: 0.2274 - val_accuracy: 0.9343\n",
      "Epoch 7/50\n",
      "84/84 [==============================] - 3s 31ms/step - loss: 0.2309 - accuracy: 0.9320 - val_loss: 0.2090 - val_accuracy: 0.9413\n",
      "Epoch 8/50\n",
      "84/84 [==============================] - 3s 32ms/step - loss: 0.2161 - accuracy: 0.9370 - val_loss: 0.1968 - val_accuracy: 0.9455\n",
      "Epoch 9/50\n",
      "84/84 [==============================] - 3s 31ms/step - loss: 0.2034 - accuracy: 0.9404 - val_loss: 0.2042 - val_accuracy: 0.9424\n",
      "Epoch 10/50\n",
      "84/84 [==============================] - 3s 32ms/step - loss: 0.1907 - accuracy: 0.9444 - val_loss: 0.1828 - val_accuracy: 0.9482\n",
      "Epoch 11/50\n",
      "84/84 [==============================] - 3s 31ms/step - loss: 0.1774 - accuracy: 0.9475 - val_loss: 0.1707 - val_accuracy: 0.9530\n",
      "Epoch 12/50\n",
      "84/84 [==============================] - 3s 32ms/step - loss: 0.1628 - accuracy: 0.9520 - val_loss: 0.1635 - val_accuracy: 0.9532\n",
      "Epoch 13/50\n",
      "84/84 [==============================] - 3s 31ms/step - loss: 0.1541 - accuracy: 0.9542 - val_loss: 0.1535 - val_accuracy: 0.9549\n",
      "Epoch 14/50\n",
      "84/84 [==============================] - 3s 31ms/step - loss: 0.1448 - accuracy: 0.9572 - val_loss: 0.1501 - val_accuracy: 0.9586\n",
      "Epoch 15/50\n",
      "84/84 [==============================] - 3s 32ms/step - loss: 0.1348 - accuracy: 0.9608 - val_loss: 0.1433 - val_accuracy: 0.9600\n",
      "Epoch 16/50\n",
      "84/84 [==============================] - 3s 37ms/step - loss: 0.1268 - accuracy: 0.9629 - val_loss: 0.1356 - val_accuracy: 0.9611\n",
      "Epoch 17/50\n",
      "84/84 [==============================] - 3s 31ms/step - loss: 0.1187 - accuracy: 0.9652 - val_loss: 0.1438 - val_accuracy: 0.9575\n",
      "Epoch 18/50\n",
      "84/84 [==============================] - 3s 32ms/step - loss: 0.1128 - accuracy: 0.9669 - val_loss: 0.1245 - val_accuracy: 0.9644\n",
      "Epoch 19/50\n",
      "84/84 [==============================] - 3s 34ms/step - loss: 0.1045 - accuracy: 0.9691 - val_loss: 0.1190 - val_accuracy: 0.9656\n",
      "Epoch 20/50\n",
      "84/84 [==============================] - 3s 33ms/step - loss: 0.0965 - accuracy: 0.9721 - val_loss: 0.1182 - val_accuracy: 0.9666\n",
      "Epoch 21/50\n",
      "84/84 [==============================] - 3s 29ms/step - loss: 0.0905 - accuracy: 0.9737 - val_loss: 0.1119 - val_accuracy: 0.9676\n",
      "Epoch 22/50\n",
      "84/84 [==============================] - 3s 29ms/step - loss: 0.0843 - accuracy: 0.9753 - val_loss: 0.1080 - val_accuracy: 0.9682\n",
      "Epoch 23/50\n",
      "84/84 [==============================] - 3s 31ms/step - loss: 0.0804 - accuracy: 0.9765 - val_loss: 0.1059 - val_accuracy: 0.9698\n",
      "Epoch 24/50\n",
      "84/84 [==============================] - 3s 32ms/step - loss: 0.0750 - accuracy: 0.9781 - val_loss: 0.1035 - val_accuracy: 0.9694\n",
      "Epoch 25/50\n",
      "84/84 [==============================] - 3s 31ms/step - loss: 0.0693 - accuracy: 0.9800 - val_loss: 0.1096 - val_accuracy: 0.9695\n",
      "Epoch 26/50\n",
      "84/84 [==============================] - 3s 32ms/step - loss: 0.0656 - accuracy: 0.9803 - val_loss: 0.0948 - val_accuracy: 0.9707\n",
      "Epoch 27/50\n",
      "84/84 [==============================] - 3s 31ms/step - loss: 0.0608 - accuracy: 0.9820 - val_loss: 0.0965 - val_accuracy: 0.9728\n",
      "Epoch 28/50\n",
      "84/84 [==============================] - 3s 31ms/step - loss: 0.0565 - accuracy: 0.9834 - val_loss: 0.0916 - val_accuracy: 0.9738\n",
      "Epoch 29/50\n",
      "84/84 [==============================] - 3s 30ms/step - loss: 0.0519 - accuracy: 0.9852 - val_loss: 0.0898 - val_accuracy: 0.9742\n",
      "Epoch 30/50\n",
      "84/84 [==============================] - 3s 30ms/step - loss: 0.0488 - accuracy: 0.9859 - val_loss: 0.0873 - val_accuracy: 0.9749\n",
      "Epoch 31/50\n",
      "84/84 [==============================] - 3s 31ms/step - loss: 0.0459 - accuracy: 0.9868 - val_loss: 0.0934 - val_accuracy: 0.9735\n",
      "Epoch 32/50\n",
      "84/84 [==============================] - 3s 31ms/step - loss: 0.0436 - accuracy: 0.9877 - val_loss: 0.0883 - val_accuracy: 0.9731\n",
      "Epoch 33/50\n",
      "84/84 [==============================] - 3s 30ms/step - loss: 0.0404 - accuracy: 0.9887 - val_loss: 0.0829 - val_accuracy: 0.9758\n",
      "Epoch 34/50\n",
      "84/84 [==============================] - 3s 29ms/step - loss: 0.0361 - accuracy: 0.9901 - val_loss: 0.0870 - val_accuracy: 0.9756\n",
      "Epoch 35/50\n",
      "84/84 [==============================] - 3s 31ms/step - loss: 0.0332 - accuracy: 0.9914 - val_loss: 0.0840 - val_accuracy: 0.9753\n",
      "Epoch 36/50\n",
      "84/84 [==============================] - 2s 29ms/step - loss: 0.0310 - accuracy: 0.9915 - val_loss: 0.0865 - val_accuracy: 0.9754\n",
      "Epoch 37/50\n",
      "84/84 [==============================] - 2s 28ms/step - loss: 0.0294 - accuracy: 0.9921 - val_loss: 0.0851 - val_accuracy: 0.9758\n",
      "Epoch 38/50\n",
      "84/84 [==============================] - 2s 29ms/step - loss: 0.0287 - accuracy: 0.9922 - val_loss: 0.0855 - val_accuracy: 0.9762\n",
      "Epoch 39/50\n",
      "84/84 [==============================] - 3s 30ms/step - loss: 0.0251 - accuracy: 0.9935 - val_loss: 0.0809 - val_accuracy: 0.9772\n",
      "Epoch 40/50\n",
      "84/84 [==============================] - 2s 28ms/step - loss: 0.0232 - accuracy: 0.9943 - val_loss: 0.0829 - val_accuracy: 0.9760\n",
      "Epoch 41/50\n",
      "84/84 [==============================] - 2s 28ms/step - loss: 0.0220 - accuracy: 0.9941 - val_loss: 0.0827 - val_accuracy: 0.9762\n",
      "Epoch 42/50\n",
      "84/84 [==============================] - 3s 30ms/step - loss: 0.0193 - accuracy: 0.9955 - val_loss: 0.0831 - val_accuracy: 0.9768\n",
      "Epoch 43/50\n",
      "84/84 [==============================] - 3s 29ms/step - loss: 0.0176 - accuracy: 0.9964 - val_loss: 0.0835 - val_accuracy: 0.9766\n",
      "Epoch 44/50\n",
      "84/84 [==============================] - 3s 30ms/step - loss: 0.0169 - accuracy: 0.9957 - val_loss: 0.0848 - val_accuracy: 0.9773\n",
      "Epoch 45/50\n",
      "84/84 [==============================] - 3s 29ms/step - loss: 0.0150 - accuracy: 0.9969 - val_loss: 0.0826 - val_accuracy: 0.9778\n",
      "Epoch 46/50\n",
      "84/84 [==============================] - 3s 29ms/step - loss: 0.0142 - accuracy: 0.9970 - val_loss: 0.0831 - val_accuracy: 0.9766\n",
      "Epoch 47/50\n",
      "84/84 [==============================] - 3s 30ms/step - loss: 0.0130 - accuracy: 0.9973 - val_loss: 0.0863 - val_accuracy: 0.9774\n",
      "Epoch 48/50\n",
      "84/84 [==============================] - 3s 29ms/step - loss: 0.0117 - accuracy: 0.9981 - val_loss: 0.0855 - val_accuracy: 0.9783\n",
      "Epoch 49/50\n",
      "84/84 [==============================] - 3s 31ms/step - loss: 0.0107 - accuracy: 0.9981 - val_loss: 0.0811 - val_accuracy: 0.9793\n",
      "Epoch 50/50\n",
      "84/84 [==============================] - 3s 31ms/step - loss: 0.0100 - accuracy: 0.9982 - val_loss: 0.0857 - val_accuracy: 0.9769\n",
      "Listo!\n",
      "Precisión de validación actual: 97.69%\n",
      "Tiempo de entrenamiento: 132.87 segundos\n",
      "Entrenando modelo con TAMANIO_TANDA=600, TAMANIO_CAPA_ESCONDIDA=1408, TASA_APRENDIZAJE=0.0004782969, NUMERO_EPOCAS=55...\n",
      "Epoch 1/55\n",
      "84/84 [==============================] - 3s 36ms/step - loss: 1.3177 - accuracy: 0.6310 - val_loss: 0.4817 - val_accuracy: 0.8826\n",
      "Epoch 2/55\n",
      "84/84 [==============================] - 3s 35ms/step - loss: 0.4119 - accuracy: 0.8873 - val_loss: 0.3173 - val_accuracy: 0.9105\n",
      "Epoch 3/55\n",
      "84/84 [==============================] - 3s 33ms/step - loss: 0.3226 - accuracy: 0.9071 - val_loss: 0.2765 - val_accuracy: 0.9200\n",
      "Epoch 4/55\n",
      "84/84 [==============================] - 3s 33ms/step - loss: 0.2905 - accuracy: 0.9163 - val_loss: 0.2614 - val_accuracy: 0.9266\n",
      "Epoch 5/55\n",
      "84/84 [==============================] - 3s 35ms/step - loss: 0.2723 - accuracy: 0.9212 - val_loss: 0.2465 - val_accuracy: 0.9287\n",
      "Epoch 6/55\n",
      "84/84 [==============================] - 3s 33ms/step - loss: 0.2558 - accuracy: 0.9250 - val_loss: 0.2393 - val_accuracy: 0.9297\n",
      "Epoch 7/55\n",
      "84/84 [==============================] - 3s 34ms/step - loss: 0.2443 - accuracy: 0.9288 - val_loss: 0.2325 - val_accuracy: 0.9317\n",
      "Epoch 8/55\n",
      "84/84 [==============================] - 3s 35ms/step - loss: 0.2267 - accuracy: 0.9337 - val_loss: 0.2067 - val_accuracy: 0.9414\n",
      "Epoch 9/55\n",
      "84/84 [==============================] - 3s 34ms/step - loss: 0.2145 - accuracy: 0.9365 - val_loss: 0.1966 - val_accuracy: 0.9439\n",
      "Epoch 10/55\n",
      "84/84 [==============================] - 3s 35ms/step - loss: 0.2007 - accuracy: 0.9407 - val_loss: 0.1961 - val_accuracy: 0.9441\n",
      "Epoch 11/55\n",
      "84/84 [==============================] - 3s 34ms/step - loss: 0.1887 - accuracy: 0.9455 - val_loss: 0.1764 - val_accuracy: 0.9514\n",
      "Epoch 12/55\n",
      "84/84 [==============================] - 3s 32ms/step - loss: 0.1763 - accuracy: 0.9476 - val_loss: 0.1732 - val_accuracy: 0.9519\n",
      "Epoch 13/55\n",
      "84/84 [==============================] - 3s 33ms/step - loss: 0.1655 - accuracy: 0.9513 - val_loss: 0.1648 - val_accuracy: 0.9531\n",
      "Epoch 14/55\n",
      "84/84 [==============================] - 3s 33ms/step - loss: 0.1546 - accuracy: 0.9544 - val_loss: 0.1603 - val_accuracy: 0.9544\n",
      "Epoch 15/55\n",
      "84/84 [==============================] - 3s 35ms/step - loss: 0.1485 - accuracy: 0.9560 - val_loss: 0.1507 - val_accuracy: 0.9566\n",
      "Epoch 16/55\n",
      "84/84 [==============================] - 3s 36ms/step - loss: 0.1376 - accuracy: 0.9596 - val_loss: 0.1421 - val_accuracy: 0.9610\n",
      "Epoch 17/55\n",
      "84/84 [==============================] - 3s 35ms/step - loss: 0.1293 - accuracy: 0.9621 - val_loss: 0.1430 - val_accuracy: 0.9596\n",
      "Epoch 18/55\n",
      "84/84 [==============================] - 3s 37ms/step - loss: 0.1220 - accuracy: 0.9638 - val_loss: 0.1334 - val_accuracy: 0.9624\n",
      "Epoch 19/55\n",
      "84/84 [==============================] - 3s 33ms/step - loss: 0.1154 - accuracy: 0.9652 - val_loss: 0.1336 - val_accuracy: 0.9605\n",
      "Epoch 20/55\n",
      "84/84 [==============================] - 3s 32ms/step - loss: 0.1082 - accuracy: 0.9686 - val_loss: 0.1255 - val_accuracy: 0.9633\n",
      "Epoch 21/55\n",
      "84/84 [==============================] - 3s 32ms/step - loss: 0.1008 - accuracy: 0.9704 - val_loss: 0.1201 - val_accuracy: 0.9663\n",
      "Epoch 22/55\n",
      "84/84 [==============================] - 3s 35ms/step - loss: 0.0951 - accuracy: 0.9721 - val_loss: 0.1149 - val_accuracy: 0.9660\n",
      "Epoch 23/55\n",
      "84/84 [==============================] - 3s 33ms/step - loss: 0.0898 - accuracy: 0.9736 - val_loss: 0.1084 - val_accuracy: 0.9682\n",
      "Epoch 24/55\n",
      "84/84 [==============================] - 3s 32ms/step - loss: 0.0842 - accuracy: 0.9754 - val_loss: 0.1089 - val_accuracy: 0.9688\n",
      "Epoch 25/55\n",
      "84/84 [==============================] - 3s 35ms/step - loss: 0.0804 - accuracy: 0.9763 - val_loss: 0.1069 - val_accuracy: 0.9689\n",
      "Epoch 26/55\n",
      "84/84 [==============================] - 3s 33ms/step - loss: 0.0736 - accuracy: 0.9786 - val_loss: 0.1004 - val_accuracy: 0.9705\n",
      "Epoch 27/55\n",
      "84/84 [==============================] - 3s 33ms/step - loss: 0.0721 - accuracy: 0.9785 - val_loss: 0.1115 - val_accuracy: 0.9663\n",
      "Epoch 28/55\n",
      "84/84 [==============================] - 3s 35ms/step - loss: 0.0670 - accuracy: 0.9796 - val_loss: 0.0977 - val_accuracy: 0.9714\n",
      "Epoch 29/55\n",
      "84/84 [==============================] - 3s 33ms/step - loss: 0.0613 - accuracy: 0.9819 - val_loss: 0.0964 - val_accuracy: 0.9731\n",
      "Epoch 30/55\n",
      "84/84 [==============================] - 3s 34ms/step - loss: 0.0588 - accuracy: 0.9822 - val_loss: 0.0917 - val_accuracy: 0.9739\n",
      "Epoch 31/55\n",
      "84/84 [==============================] - 3s 33ms/step - loss: 0.0530 - accuracy: 0.9845 - val_loss: 0.0914 - val_accuracy: 0.9740\n",
      "Epoch 32/55\n",
      "84/84 [==============================] - 3s 33ms/step - loss: 0.0509 - accuracy: 0.9852 - val_loss: 0.0902 - val_accuracy: 0.9725\n",
      "Epoch 33/55\n",
      "84/84 [==============================] - 3s 33ms/step - loss: 0.0473 - accuracy: 0.9858 - val_loss: 0.0894 - val_accuracy: 0.9739\n",
      "Epoch 34/55\n",
      "84/84 [==============================] - 3s 34ms/step - loss: 0.0444 - accuracy: 0.9870 - val_loss: 0.0864 - val_accuracy: 0.9748\n",
      "Epoch 35/55\n",
      "84/84 [==============================] - 3s 34ms/step - loss: 0.0407 - accuracy: 0.9885 - val_loss: 0.0855 - val_accuracy: 0.9749\n",
      "Epoch 36/55\n",
      "84/84 [==============================] - 3s 36ms/step - loss: 0.0397 - accuracy: 0.9889 - val_loss: 0.0850 - val_accuracy: 0.9746\n",
      "Epoch 37/55\n",
      "84/84 [==============================] - 3s 37ms/step - loss: 0.0360 - accuracy: 0.9899 - val_loss: 0.0828 - val_accuracy: 0.9758\n",
      "Epoch 38/55\n",
      "84/84 [==============================] - 3s 35ms/step - loss: 0.0339 - accuracy: 0.9910 - val_loss: 0.0812 - val_accuracy: 0.9756\n",
      "Epoch 39/55\n",
      "84/84 [==============================] - 3s 34ms/step - loss: 0.0318 - accuracy: 0.9910 - val_loss: 0.0830 - val_accuracy: 0.9747\n",
      "Epoch 40/55\n",
      "84/84 [==============================] - 3s 33ms/step - loss: 0.0282 - accuracy: 0.9927 - val_loss: 0.0819 - val_accuracy: 0.9765\n",
      "Epoch 41/55\n",
      "84/84 [==============================] - 3s 32ms/step - loss: 0.0268 - accuracy: 0.9931 - val_loss: 0.0818 - val_accuracy: 0.9762\n",
      "Epoch 42/55\n",
      "84/84 [==============================] - 3s 35ms/step - loss: 0.0253 - accuracy: 0.9930 - val_loss: 0.0896 - val_accuracy: 0.9756\n",
      "Epoch 43/55\n",
      "84/84 [==============================] - 3s 35ms/step - loss: 0.0249 - accuracy: 0.9934 - val_loss: 0.0830 - val_accuracy: 0.9766\n",
      "Epoch 44/55\n",
      "84/84 [==============================] - 3s 34ms/step - loss: 0.0211 - accuracy: 0.9952 - val_loss: 0.0813 - val_accuracy: 0.9762\n",
      "Epoch 45/55\n",
      "84/84 [==============================] - 3s 34ms/step - loss: 0.0206 - accuracy: 0.9950 - val_loss: 0.0816 - val_accuracy: 0.9771\n",
      "Epoch 46/55\n",
      "84/84 [==============================] - 3s 37ms/step - loss: 0.0188 - accuracy: 0.9957 - val_loss: 0.0851 - val_accuracy: 0.9765\n",
      "Epoch 47/55\n",
      "84/84 [==============================] - 3s 35ms/step - loss: 0.0169 - accuracy: 0.9966 - val_loss: 0.0858 - val_accuracy: 0.9770\n",
      "Epoch 48/55\n",
      "84/84 [==============================] - 3s 33ms/step - loss: 0.0168 - accuracy: 0.9963 - val_loss: 0.0851 - val_accuracy: 0.9776\n",
      "Epoch 49/55\n",
      "84/84 [==============================] - 3s 35ms/step - loss: 0.0155 - accuracy: 0.9965 - val_loss: 0.0870 - val_accuracy: 0.9767\n",
      "Epoch 50/55\n",
      "84/84 [==============================] - 3s 37ms/step - loss: 0.0142 - accuracy: 0.9969 - val_loss: 0.0794 - val_accuracy: 0.9784\n",
      "Epoch 51/55\n",
      "84/84 [==============================] - 3s 32ms/step - loss: 0.0130 - accuracy: 0.9972 - val_loss: 0.0805 - val_accuracy: 0.9783\n",
      "Epoch 52/55\n",
      "84/84 [==============================] - 3s 31ms/step - loss: 0.0125 - accuracy: 0.9972 - val_loss: 0.0835 - val_accuracy: 0.9781\n",
      "Epoch 53/55\n",
      "84/84 [==============================] - 3s 35ms/step - loss: 0.0111 - accuracy: 0.9977 - val_loss: 0.0846 - val_accuracy: 0.9750\n",
      "Epoch 54/55\n",
      "84/84 [==============================] - 3s 35ms/step - loss: 0.0110 - accuracy: 0.9977 - val_loss: 0.0811 - val_accuracy: 0.9785\n",
      "Epoch 55/55\n",
      "84/84 [==============================] - 3s 35ms/step - loss: 0.0091 - accuracy: 0.9985 - val_loss: 0.0819 - val_accuracy: 0.9788\n",
      "Listo!\n",
      "Precisión de validación actual: 97.88%\n",
      "Tiempo de entrenamiento: 162.53 segundos\n",
      "Entrenando modelo con TAMANIO_TANDA=600, TAMANIO_CAPA_ESCONDIDA=1536, TASA_APRENDIZAJE=0.00043046721, NUMERO_EPOCAS=60...\n",
      "Epoch 1/60\n",
      "84/84 [==============================] - 4s 43ms/step - loss: 1.3164 - accuracy: 0.6314 - val_loss: 0.4915 - val_accuracy: 0.8725\n",
      "Epoch 2/60\n",
      "84/84 [==============================] - 3s 40ms/step - loss: 0.4155 - accuracy: 0.8849 - val_loss: 0.3183 - val_accuracy: 0.9083\n",
      "Epoch 3/60\n",
      "84/84 [==============================] - 3s 39ms/step - loss: 0.3278 - accuracy: 0.9049 - val_loss: 0.2889 - val_accuracy: 0.9123\n",
      "Epoch 4/60\n",
      "84/84 [==============================] - 3s 39ms/step - loss: 0.2979 - accuracy: 0.9131 - val_loss: 0.2690 - val_accuracy: 0.9196\n",
      "Epoch 5/60\n",
      "84/84 [==============================] - 3s 39ms/step - loss: 0.2743 - accuracy: 0.9204 - val_loss: 0.2535 - val_accuracy: 0.9257\n",
      "Epoch 6/60\n",
      "84/84 [==============================] - 3s 39ms/step - loss: 0.2636 - accuracy: 0.9237 - val_loss: 0.2430 - val_accuracy: 0.9288\n",
      "Epoch 7/60\n",
      "84/84 [==============================] - 3s 38ms/step - loss: 0.2478 - accuracy: 0.9277 - val_loss: 0.2289 - val_accuracy: 0.9345\n",
      "Epoch 8/60\n",
      "84/84 [==============================] - 3s 39ms/step - loss: 0.2336 - accuracy: 0.9322 - val_loss: 0.2168 - val_accuracy: 0.9390\n",
      "Epoch 9/60\n",
      "84/84 [==============================] - 3s 37ms/step - loss: 0.2228 - accuracy: 0.9341 - val_loss: 0.2034 - val_accuracy: 0.9419\n",
      "Epoch 10/60\n",
      "84/84 [==============================] - 3s 38ms/step - loss: 0.2103 - accuracy: 0.9380 - val_loss: 0.1986 - val_accuracy: 0.9436\n",
      "Epoch 11/60\n",
      "84/84 [==============================] - 3s 38ms/step - loss: 0.1979 - accuracy: 0.9416 - val_loss: 0.1875 - val_accuracy: 0.9482\n",
      "Epoch 12/60\n",
      "84/84 [==============================] - 3s 38ms/step - loss: 0.1864 - accuracy: 0.9456 - val_loss: 0.1799 - val_accuracy: 0.9506\n",
      "Epoch 13/60\n",
      "84/84 [==============================] - 3s 39ms/step - loss: 0.1755 - accuracy: 0.9487 - val_loss: 0.1745 - val_accuracy: 0.9536\n",
      "Epoch 14/60\n",
      "84/84 [==============================] - 3s 39ms/step - loss: 0.1679 - accuracy: 0.9496 - val_loss: 0.1712 - val_accuracy: 0.9501\n",
      "Epoch 15/60\n",
      "84/84 [==============================] - 3s 36ms/step - loss: 0.1568 - accuracy: 0.9536 - val_loss: 0.1566 - val_accuracy: 0.9563\n",
      "Epoch 16/60\n",
      "84/84 [==============================] - 3s 40ms/step - loss: 0.1473 - accuracy: 0.9563 - val_loss: 0.1490 - val_accuracy: 0.9581\n",
      "Epoch 17/60\n",
      "84/84 [==============================] - 3s 39ms/step - loss: 0.1397 - accuracy: 0.9586 - val_loss: 0.1498 - val_accuracy: 0.9585\n",
      "Epoch 18/60\n",
      "84/84 [==============================] - 3s 39ms/step - loss: 0.1301 - accuracy: 0.9619 - val_loss: 0.1379 - val_accuracy: 0.9602\n",
      "Epoch 19/60\n",
      "84/84 [==============================] - 3s 40ms/step - loss: 0.1229 - accuracy: 0.9641 - val_loss: 0.1347 - val_accuracy: 0.9619\n",
      "Epoch 20/60\n",
      "84/84 [==============================] - 3s 40ms/step - loss: 0.1168 - accuracy: 0.9661 - val_loss: 0.1299 - val_accuracy: 0.9635\n",
      "Epoch 21/60\n",
      "84/84 [==============================] - 3s 39ms/step - loss: 0.1105 - accuracy: 0.9680 - val_loss: 0.1258 - val_accuracy: 0.9644\n",
      "Epoch 22/60\n",
      "84/84 [==============================] - 3s 40ms/step - loss: 0.1066 - accuracy: 0.9688 - val_loss: 0.1241 - val_accuracy: 0.9658\n",
      "Epoch 23/60\n",
      "84/84 [==============================] - 3s 39ms/step - loss: 0.0997 - accuracy: 0.9707 - val_loss: 0.1214 - val_accuracy: 0.9669\n",
      "Epoch 24/60\n",
      "84/84 [==============================] - 3s 38ms/step - loss: 0.0930 - accuracy: 0.9722 - val_loss: 0.1140 - val_accuracy: 0.9673\n",
      "Epoch 25/60\n",
      "84/84 [==============================] - 3s 40ms/step - loss: 0.0883 - accuracy: 0.9739 - val_loss: 0.1120 - val_accuracy: 0.9684\n",
      "Epoch 26/60\n",
      "84/84 [==============================] - 3s 40ms/step - loss: 0.0828 - accuracy: 0.9761 - val_loss: 0.1062 - val_accuracy: 0.9689\n",
      "Epoch 27/60\n",
      "84/84 [==============================] - 3s 40ms/step - loss: 0.0779 - accuracy: 0.9775 - val_loss: 0.1096 - val_accuracy: 0.9703\n",
      "Epoch 28/60\n",
      "84/84 [==============================] - 4s 41ms/step - loss: 0.0752 - accuracy: 0.9779 - val_loss: 0.1042 - val_accuracy: 0.9702\n",
      "Epoch 29/60\n",
      "84/84 [==============================] - 3s 39ms/step - loss: 0.0699 - accuracy: 0.9799 - val_loss: 0.1019 - val_accuracy: 0.9698\n",
      "Epoch 30/60\n",
      "84/84 [==============================] - 3s 39ms/step - loss: 0.0667 - accuracy: 0.9804 - val_loss: 0.1022 - val_accuracy: 0.9697\n",
      "Epoch 31/60\n",
      "84/84 [==============================] - 3s 40ms/step - loss: 0.0633 - accuracy: 0.9815 - val_loss: 0.0959 - val_accuracy: 0.9712\n",
      "Epoch 32/60\n",
      "84/84 [==============================] - 4s 42ms/step - loss: 0.0582 - accuracy: 0.9833 - val_loss: 0.0968 - val_accuracy: 0.9704\n",
      "Epoch 33/60\n",
      "84/84 [==============================] - 4s 42ms/step - loss: 0.0551 - accuracy: 0.9836 - val_loss: 0.0946 - val_accuracy: 0.9718\n",
      "Epoch 34/60\n",
      "84/84 [==============================] - 4s 42ms/step - loss: 0.0513 - accuracy: 0.9852 - val_loss: 0.0898 - val_accuracy: 0.9731\n",
      "Epoch 35/60\n",
      "84/84 [==============================] - 3s 39ms/step - loss: 0.0490 - accuracy: 0.9859 - val_loss: 0.0906 - val_accuracy: 0.9728\n",
      "Epoch 36/60\n",
      "84/84 [==============================] - 3s 40ms/step - loss: 0.0461 - accuracy: 0.9866 - val_loss: 0.0912 - val_accuracy: 0.9732\n",
      "Epoch 37/60\n",
      "84/84 [==============================] - 3s 39ms/step - loss: 0.0444 - accuracy: 0.9871 - val_loss: 0.0871 - val_accuracy: 0.9734\n",
      "Epoch 38/60\n",
      "84/84 [==============================] - 3s 40ms/step - loss: 0.0401 - accuracy: 0.9888 - val_loss: 0.0840 - val_accuracy: 0.9756\n",
      "Epoch 39/60\n",
      "84/84 [==============================] - 3s 40ms/step - loss: 0.0385 - accuracy: 0.9891 - val_loss: 0.0838 - val_accuracy: 0.9752\n",
      "Epoch 40/60\n",
      "84/84 [==============================] - 3s 39ms/step - loss: 0.0361 - accuracy: 0.9900 - val_loss: 0.0899 - val_accuracy: 0.9731\n",
      "Epoch 41/60\n",
      "84/84 [==============================] - 3s 38ms/step - loss: 0.0342 - accuracy: 0.9905 - val_loss: 0.0865 - val_accuracy: 0.9751\n",
      "Epoch 42/60\n",
      "84/84 [==============================] - 3s 38ms/step - loss: 0.0303 - accuracy: 0.9920 - val_loss: 0.0813 - val_accuracy: 0.9755\n",
      "Epoch 43/60\n",
      "84/84 [==============================] - 3s 37ms/step - loss: 0.0279 - accuracy: 0.9927 - val_loss: 0.0824 - val_accuracy: 0.9755\n",
      "Epoch 44/60\n",
      "84/84 [==============================] - 3s 37ms/step - loss: 0.0293 - accuracy: 0.9920 - val_loss: 0.0860 - val_accuracy: 0.9754\n",
      "Epoch 45/60\n",
      "84/84 [==============================] - 3s 37ms/step - loss: 0.0251 - accuracy: 0.9936 - val_loss: 0.0808 - val_accuracy: 0.9768\n",
      "Epoch 46/60\n",
      "84/84 [==============================] - 3s 39ms/step - loss: 0.0226 - accuracy: 0.9944 - val_loss: 0.0811 - val_accuracy: 0.9773\n",
      "Epoch 47/60\n",
      "84/84 [==============================] - 3s 38ms/step - loss: 0.0215 - accuracy: 0.9952 - val_loss: 0.0842 - val_accuracy: 0.9756\n",
      "Epoch 48/60\n",
      "84/84 [==============================] - 3s 39ms/step - loss: 0.0219 - accuracy: 0.9944 - val_loss: 0.0806 - val_accuracy: 0.9772\n",
      "Epoch 49/60\n",
      "84/84 [==============================] - 3s 39ms/step - loss: 0.0199 - accuracy: 0.9953 - val_loss: 0.0824 - val_accuracy: 0.9762\n",
      "Epoch 50/60\n",
      "84/84 [==============================] - 3s 39ms/step - loss: 0.0169 - accuracy: 0.9962 - val_loss: 0.0832 - val_accuracy: 0.9771\n",
      "Epoch 51/60\n",
      "84/84 [==============================] - 3s 38ms/step - loss: 0.0176 - accuracy: 0.9958 - val_loss: 0.0806 - val_accuracy: 0.9773\n",
      "Epoch 52/60\n",
      "84/84 [==============================] - 3s 37ms/step - loss: 0.0150 - accuracy: 0.9972 - val_loss: 0.0808 - val_accuracy: 0.9782\n",
      "Epoch 53/60\n",
      "84/84 [==============================] - 3s 38ms/step - loss: 0.0143 - accuracy: 0.9971 - val_loss: 0.0815 - val_accuracy: 0.9771\n",
      "Epoch 54/60\n",
      "84/84 [==============================] - 3s 38ms/step - loss: 0.0126 - accuracy: 0.9976 - val_loss: 0.0812 - val_accuracy: 0.9773\n",
      "Epoch 55/60\n",
      "84/84 [==============================] - 4s 41ms/step - loss: 0.0118 - accuracy: 0.9978 - val_loss: 0.0809 - val_accuracy: 0.9780\n",
      "Epoch 56/60\n",
      "84/84 [==============================] - 4s 42ms/step - loss: 0.0113 - accuracy: 0.9978 - val_loss: 0.0831 - val_accuracy: 0.9789\n",
      "Epoch 57/60\n",
      "84/84 [==============================] - 3s 39ms/step - loss: 0.0106 - accuracy: 0.9979 - val_loss: 0.0831 - val_accuracy: 0.9788\n",
      "Epoch 58/60\n",
      "84/84 [==============================] - 3s 39ms/step - loss: 0.0099 - accuracy: 0.9982 - val_loss: 0.0820 - val_accuracy: 0.9786\n",
      "Epoch 59/60\n",
      "84/84 [==============================] - 3s 39ms/step - loss: 0.0087 - accuracy: 0.9986 - val_loss: 0.0824 - val_accuracy: 0.9784\n",
      "Epoch 60/60\n",
      "84/84 [==============================] - 3s 40ms/step - loss: 0.0084 - accuracy: 0.9985 - val_loss: 0.0841 - val_accuracy: 0.9785\n",
      "Listo!\n",
      "Precisión de validación actual: 97.85%\n",
      "Tiempo de entrenamiento: 202.35 segundos\n",
      "Entrenando modelo con TAMANIO_TANDA=600, TAMANIO_CAPA_ESCONDIDA=1664, TASA_APRENDIZAJE=0.000387420489, NUMERO_EPOCAS=65...\n",
      "Epoch 1/65\n",
      "84/84 [==============================] - 4s 46ms/step - loss: 1.3109 - accuracy: 0.6434 - val_loss: 0.5149 - val_accuracy: 0.8659\n",
      "Epoch 2/65\n",
      "84/84 [==============================] - 4s 44ms/step - loss: 0.4287 - accuracy: 0.8822 - val_loss: 0.3251 - val_accuracy: 0.9078\n",
      "Epoch 3/65\n",
      "84/84 [==============================] - 4s 45ms/step - loss: 0.3339 - accuracy: 0.9037 - val_loss: 0.2922 - val_accuracy: 0.9156\n",
      "Epoch 4/65\n",
      "84/84 [==============================] - 4s 45ms/step - loss: 0.2997 - accuracy: 0.9130 - val_loss: 0.2644 - val_accuracy: 0.9250\n",
      "Epoch 5/65\n",
      "46/84 [===============>..............] - ETA: 1s - loss: 0.2851 - accuracy: 0.9170"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 56\u001b[0m\n\u001b[0;32m     53\u001b[0m precision_validacion_actual \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m precision_validacion_actual \u001b[38;5;241m<\u001b[39m precision_objetivo:\n\u001b[1;32m---> 56\u001b[0m     precision_validacion_actual, tiempo_entrenamiento \u001b[38;5;241m=\u001b[39m \u001b[43mentrenar_y_evaluar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTAMANIO_TANDA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTAMANIO_CAPA_ESCONDIDA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTASA_APRENDIZAJE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNUMERO_EPOCAS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     58\u001b[0m     \u001b[38;5;66;03m# Ajustar parámetros si no se alcanza la precisión objetivo\u001b[39;00m\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m precision_validacion_actual \u001b[38;5;241m<\u001b[39m precision_objetivo:\n",
      "Cell \u001b[1;32mIn[33], line 35\u001b[0m, in \u001b[0;36mentrenar_y_evaluar\u001b[1;34m(TAMANIO_TANDA, TAMANIO_CAPA_ESCONDIDA, TASA_APRENDIZAJE, NUMERO_EPOCAS)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEntrenando modelo con TAMANIO_TANDA=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mTAMANIO_TANDA\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, TAMANIO_CAPA_ESCONDIDA=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mTAMANIO_CAPA_ESCONDIDA\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, TASA_APRENDIZAJE=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mTASA_APRENDIZAJE\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, NUMERO_EPOCAS=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mNUMERO_EPOCAS\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     34\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m---> 35\u001b[0m historia \u001b[38;5;241m=\u001b[39m \u001b[43mmodelo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdatos_entreno\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNUMERO_EPOCAS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatos_validacion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     37\u001b[0m tiempo_entrenamiento \u001b[38;5;241m=\u001b[39m end \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[1;32mc:\\Users\\caste\\anaconda3\\envs\\base9\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\caste\\anaconda3\\envs\\base9\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\caste\\anaconda3\\envs\\base9\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\caste\\anaconda3\\envs\\base9\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\caste\\anaconda3\\envs\\base9\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\caste\\anaconda3\\envs\\base9\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\caste\\anaconda3\\envs\\base9\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\caste\\anaconda3\\envs\\base9\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\caste\\anaconda3\\envs\\base9\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import time\n",
    "\n",
    "# Función para entrenar y evaluar el modelo\n",
    "def entrenar_y_evaluar(TAMANIO_TANDA, TAMANIO_CAPA_ESCONDIDA, TASA_APRENDIZAJE, NUMERO_EPOCAS):\n",
    "    # Reestablecer los conjuntos de datos\n",
    "    datos_entreno = tf.data.Dataset.from_tensor_slices((X_entreno, y_entreno))\n",
    "    datos_validacion = tf.data.Dataset.from_tensor_slices((X_validacion, y_validacion))\n",
    "    datos_prueba = tf.data.Dataset.from_tensor_slices((X_prueba, y_prueba))\n",
    "\n",
    "    # Dividir en tandas los conjuntos de datos\n",
    "    datos_entreno = datos_entreno.shuffle(buffer_size=num_obs_entreno).batch(TAMANIO_TANDA)  # Barajear datos de entrenamiento\n",
    "    datos_validacion = datos_validacion.batch(TAMANIO_TANDA)\n",
    "    datos_prueba = datos_prueba.batch(TAMANIO_TANDA)\n",
    "\n",
    "    # Definimos la nueva estructura del modelo\n",
    "    modelo = tf.keras.Sequential([\n",
    "        tf.keras.Input(shape=(28, 28)),  # capas de entrada\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(TAMANIO_CAPA_ESCONDIDA, activation='sigmoid'),  # 1era capa escondida\n",
    "        tf.keras.layers.Dense(TAMANIO_CAPA_ESCONDIDA, activation='sigmoid'),  # 2nda capa escondida\n",
    "        tf.keras.layers.Dense(tamanio_salida, activation='softmax')  # capa salida\n",
    "    ])\n",
    "\n",
    "    # Crear el optimizador con la tasa de aprendizaje especificada\n",
    "    optimizador = Adam(learning_rate=TASA_APRENDIZAJE)\n",
    "\n",
    "    # Compilamos el modelo\n",
    "    modelo.compile(optimizer=optimizador, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Entrenar el modelo\n",
    "    print(f\"Entrenando modelo con TAMANIO_TANDA={TAMANIO_TANDA}, TAMANIO_CAPA_ESCONDIDA={TAMANIO_CAPA_ESCONDIDA}, TASA_APRENDIZAJE={TASA_APRENDIZAJE}, NUMERO_EPOCAS={NUMERO_EPOCAS}...\")\n",
    "    start = time.time()\n",
    "    historia = modelo.fit(datos_entreno, epochs=NUMERO_EPOCAS, validation_data=datos_validacion, verbose=1)\n",
    "    end = time.time()\n",
    "    tiempo_entrenamiento = end - start\n",
    "    print(\"Listo!\")\n",
    "\n",
    "    # Obtener la precisión de validación final\n",
    "    precision_validacion = historia.history['val_accuracy'][-1]\n",
    "\n",
    "    return precision_validacion, tiempo_entrenamiento\n",
    "\n",
    "# Parámetros iniciales\n",
    "TAMANIO_TANDA = 600\n",
    "TAMANIO_CAPA_ESCONDIDA = 512\n",
    "TASA_APRENDIZAJE = 0.001\n",
    "NUMERO_EPOCAS = 20\n",
    "\n",
    "# Bucle para ajustar los parámetros\n",
    "precision_objetivo = 0.985\n",
    "precision_validacion_actual = 0.0\n",
    "\n",
    "while precision_validacion_actual < precision_objetivo:\n",
    "    precision_validacion_actual, tiempo_entrenamiento = entrenar_y_evaluar(TAMANIO_TANDA, TAMANIO_CAPA_ESCONDIDA, TASA_APRENDIZAJE, NUMERO_EPOCAS)\n",
    "    \n",
    "    # Ajustar parámetros si no se alcanza la precisión objetivo\n",
    "    if precision_validacion_actual < precision_objetivo:\n",
    "        TAMANIO_CAPA_ESCONDIDA += 128  # Aumentar el tamaño de la capa oculta\n",
    "        TASA_APRENDIZAJE *= 0.9  # Reducir la tasa de aprendizaje\n",
    "        NUMERO_EPOCAS += 5  # Aumentar el número de épocas\n",
    "\n",
    "    print(f\"Precisión de validación actual: {precision_validacion_actual * 100:.2f}%\")\n",
    "    print(f\"Tiempo de entrenamiento: {tiempo_entrenamiento:.2f} segundos\")\n",
    "\n",
    "print(\"¡Precisión objetivo alcanzada!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo con TAMANIO_TANDA=600, TAMANIO_CAPA_ESCONDIDA=512, TASA_APRENDIZAJE=0.001, NUMERO_EPOCAS=20, NUMERO_CAPAS=2...\n",
      "Epoch 1/20\n",
      "84/84 [==============================] - 2s 14ms/step - loss: 1.0695 - accuracy: 0.7082 - val_loss: 0.3880 - val_accuracy: 0.8988\n",
      "Epoch 2/20\n",
      "84/84 [==============================] - 1s 15ms/step - loss: 0.3498 - accuracy: 0.9014 - val_loss: 0.2767 - val_accuracy: 0.9225\n",
      "Epoch 3/20\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.2802 - accuracy: 0.9181 - val_loss: 0.2428 - val_accuracy: 0.9299\n",
      "Epoch 4/20\n",
      "84/84 [==============================] - 1s 12ms/step - loss: 0.2462 - accuracy: 0.9283 - val_loss: 0.2238 - val_accuracy: 0.9367\n",
      "Epoch 5/20\n",
      "84/84 [==============================] - 1s 12ms/step - loss: 0.2192 - accuracy: 0.9352 - val_loss: 0.1924 - val_accuracy: 0.9473\n",
      "Epoch 6/20\n",
      "84/84 [==============================] - 1s 12ms/step - loss: 0.1944 - accuracy: 0.9426 - val_loss: 0.1816 - val_accuracy: 0.9493\n",
      "Epoch 7/20\n",
      "84/84 [==============================] - 1s 12ms/step - loss: 0.1758 - accuracy: 0.9482 - val_loss: 0.1636 - val_accuracy: 0.9526\n",
      "Epoch 8/20\n",
      "84/84 [==============================] - 1s 12ms/step - loss: 0.1577 - accuracy: 0.9531 - val_loss: 0.1552 - val_accuracy: 0.9563\n",
      "Epoch 9/20\n",
      "84/84 [==============================] - 1s 12ms/step - loss: 0.1428 - accuracy: 0.9580 - val_loss: 0.1402 - val_accuracy: 0.9611\n",
      "Epoch 10/20\n",
      "84/84 [==============================] - 1s 12ms/step - loss: 0.1280 - accuracy: 0.9631 - val_loss: 0.1357 - val_accuracy: 0.9615\n",
      "Epoch 11/20\n",
      "84/84 [==============================] - 1s 12ms/step - loss: 0.1160 - accuracy: 0.9666 - val_loss: 0.1238 - val_accuracy: 0.9638\n",
      "Epoch 12/20\n",
      "84/84 [==============================] - 1s 12ms/step - loss: 0.1063 - accuracy: 0.9694 - val_loss: 0.1181 - val_accuracy: 0.9668\n",
      "Epoch 13/20\n",
      "84/84 [==============================] - 1s 12ms/step - loss: 0.0959 - accuracy: 0.9720 - val_loss: 0.1085 - val_accuracy: 0.9690\n",
      "Epoch 14/20\n",
      "84/84 [==============================] - 1s 12ms/step - loss: 0.0857 - accuracy: 0.9755 - val_loss: 0.1059 - val_accuracy: 0.9695\n",
      "Epoch 15/20\n",
      "84/84 [==============================] - 1s 12ms/step - loss: 0.0800 - accuracy: 0.9773 - val_loss: 0.1001 - val_accuracy: 0.9711\n",
      "Epoch 16/20\n",
      "84/84 [==============================] - 1s 12ms/step - loss: 0.0720 - accuracy: 0.9793 - val_loss: 0.0949 - val_accuracy: 0.9726\n",
      "Epoch 17/20\n",
      "84/84 [==============================] - 1s 12ms/step - loss: 0.0650 - accuracy: 0.9817 - val_loss: 0.0933 - val_accuracy: 0.9732\n",
      "Epoch 18/20\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 0.0582 - accuracy: 0.9832 - val_loss: 0.0884 - val_accuracy: 0.9736\n",
      "Epoch 19/20\n",
      "84/84 [==============================] - 1s 12ms/step - loss: 0.0531 - accuracy: 0.9848 - val_loss: 0.0870 - val_accuracy: 0.9743\n",
      "Epoch 20/20\n",
      "84/84 [==============================] - 1s 12ms/step - loss: 0.0488 - accuracy: 0.9864 - val_loss: 0.0819 - val_accuracy: 0.9753\n",
      "Listo!\n",
      "Precisión de validación actual: 97.53%\n",
      "Tiempo de entrenamiento: 22.79 segundos\n",
      "Entrenando modelo con TAMANIO_TANDA=550, TAMANIO_CAPA_ESCONDIDA=576, TASA_APRENDIZAJE=0.00095, NUMERO_EPOCAS=22, NUMERO_CAPAS=3...\n",
      "Epoch 1/22\n",
      "91/91 [==============================] - 2s 20ms/step - loss: 1.2294 - accuracy: 0.6077 - val_loss: 0.3991 - val_accuracy: 0.8829\n",
      "Epoch 2/22\n",
      "91/91 [==============================] - 2s 18ms/step - loss: 0.3464 - accuracy: 0.8973 - val_loss: 0.2789 - val_accuracy: 0.9160\n",
      "Epoch 3/22\n",
      "91/91 [==============================] - 2s 18ms/step - loss: 0.2691 - accuracy: 0.9198 - val_loss: 0.2228 - val_accuracy: 0.9343\n",
      "Epoch 4/22\n",
      "91/91 [==============================] - 2s 18ms/step - loss: 0.2251 - accuracy: 0.9324 - val_loss: 0.1994 - val_accuracy: 0.9404\n",
      "Epoch 5/22\n",
      "91/91 [==============================] - 2s 18ms/step - loss: 0.1912 - accuracy: 0.9433 - val_loss: 0.1707 - val_accuracy: 0.9511\n",
      "Epoch 6/22\n",
      "91/91 [==============================] - 2s 18ms/step - loss: 0.1663 - accuracy: 0.9501 - val_loss: 0.1532 - val_accuracy: 0.9556\n",
      "Epoch 7/22\n",
      "91/91 [==============================] - 2s 18ms/step - loss: 0.1468 - accuracy: 0.9559 - val_loss: 0.1343 - val_accuracy: 0.9612\n",
      "Epoch 8/22\n",
      "91/91 [==============================] - 2s 18ms/step - loss: 0.1285 - accuracy: 0.9618 - val_loss: 0.1305 - val_accuracy: 0.9626\n",
      "Epoch 9/22\n",
      "91/91 [==============================] - 2s 18ms/step - loss: 0.1149 - accuracy: 0.9653 - val_loss: 0.1245 - val_accuracy: 0.9640\n",
      "Epoch 10/22\n",
      "91/91 [==============================] - 2s 18ms/step - loss: 0.1025 - accuracy: 0.9694 - val_loss: 0.1140 - val_accuracy: 0.9683\n",
      "Epoch 11/22\n",
      "91/91 [==============================] - 2s 18ms/step - loss: 0.0924 - accuracy: 0.9726 - val_loss: 0.1091 - val_accuracy: 0.9688\n",
      "Epoch 12/22\n",
      "91/91 [==============================] - 2s 18ms/step - loss: 0.0811 - accuracy: 0.9758 - val_loss: 0.1042 - val_accuracy: 0.9685\n",
      "Epoch 13/22\n",
      "91/91 [==============================] - 2s 18ms/step - loss: 0.0710 - accuracy: 0.9790 - val_loss: 0.0939 - val_accuracy: 0.9728\n",
      "Epoch 14/22\n",
      "91/91 [==============================] - 2s 18ms/step - loss: 0.0637 - accuracy: 0.9810 - val_loss: 0.0963 - val_accuracy: 0.9716\n",
      "Epoch 15/22\n",
      "91/91 [==============================] - 2s 19ms/step - loss: 0.0591 - accuracy: 0.9817 - val_loss: 0.0919 - val_accuracy: 0.9734\n",
      "Epoch 16/22\n",
      "91/91 [==============================] - 2s 18ms/step - loss: 0.0529 - accuracy: 0.9840 - val_loss: 0.0894 - val_accuracy: 0.9727\n",
      "Epoch 17/22\n",
      "91/91 [==============================] - 2s 19ms/step - loss: 0.0447 - accuracy: 0.9875 - val_loss: 0.0879 - val_accuracy: 0.9755\n",
      "Epoch 18/22\n",
      "91/91 [==============================] - 2s 18ms/step - loss: 0.0405 - accuracy: 0.9881 - val_loss: 0.0928 - val_accuracy: 0.9746\n",
      "Epoch 19/22\n",
      "91/91 [==============================] - 2s 18ms/step - loss: 0.0351 - accuracy: 0.9902 - val_loss: 0.0893 - val_accuracy: 0.9758\n",
      "Epoch 20/22\n",
      "91/91 [==============================] - 2s 19ms/step - loss: 0.0309 - accuracy: 0.9916 - val_loss: 0.0846 - val_accuracy: 0.9750\n",
      "Epoch 21/22\n",
      "91/91 [==============================] - 2s 18ms/step - loss: 0.0258 - accuracy: 0.9930 - val_loss: 0.0864 - val_accuracy: 0.9749\n",
      "Epoch 22/22\n",
      "91/91 [==============================] - 2s 18ms/step - loss: 0.0250 - accuracy: 0.9930 - val_loss: 0.0857 - val_accuracy: 0.9770\n",
      "Listo!\n",
      "Precisión de validación actual: 97.70%\n",
      "Tiempo de entrenamiento: 38.72 segundos\n",
      "Entrenando modelo con TAMANIO_TANDA=500, TAMANIO_CAPA_ESCONDIDA=640, TASA_APRENDIZAJE=0.0009025, NUMERO_EPOCAS=24, NUMERO_CAPAS=4...\n",
      "Epoch 1/24\n",
      "100/100 [==============================] - 3s 24ms/step - loss: 1.5136 - accuracy: 0.4703 - val_loss: 0.5193 - val_accuracy: 0.8481\n",
      "Epoch 2/24\n",
      "100/100 [==============================] - 2s 23ms/step - loss: 0.4184 - accuracy: 0.8767 - val_loss: 0.3339 - val_accuracy: 0.8989\n",
      "Epoch 3/24\n",
      "100/100 [==============================] - 2s 22ms/step - loss: 0.2968 - accuracy: 0.9113 - val_loss: 0.2379 - val_accuracy: 0.9284\n",
      "Epoch 4/24\n",
      "100/100 [==============================] - 2s 22ms/step - loss: 0.2342 - accuracy: 0.9293 - val_loss: 0.2039 - val_accuracy: 0.9391\n",
      "Epoch 5/24\n",
      "100/100 [==============================] - 2s 23ms/step - loss: 0.1916 - accuracy: 0.9416 - val_loss: 0.1705 - val_accuracy: 0.9510\n",
      "Epoch 6/24\n",
      "100/100 [==============================] - 2s 23ms/step - loss: 0.1655 - accuracy: 0.9495 - val_loss: 0.1411 - val_accuracy: 0.9584\n",
      "Epoch 7/24\n",
      "100/100 [==============================] - 2s 22ms/step - loss: 0.1401 - accuracy: 0.9584 - val_loss: 0.1296 - val_accuracy: 0.9635\n",
      "Epoch 8/24\n",
      "100/100 [==============================] - 2s 22ms/step - loss: 0.1215 - accuracy: 0.9634 - val_loss: 0.1206 - val_accuracy: 0.9657\n",
      "Epoch 9/24\n",
      "100/100 [==============================] - 2s 23ms/step - loss: 0.1069 - accuracy: 0.9678 - val_loss: 0.1190 - val_accuracy: 0.9651\n",
      "Epoch 10/24\n",
      "100/100 [==============================] - 2s 23ms/step - loss: 0.0968 - accuracy: 0.9701 - val_loss: 0.1137 - val_accuracy: 0.9661\n",
      "Epoch 11/24\n",
      "100/100 [==============================] - 2s 23ms/step - loss: 0.0863 - accuracy: 0.9744 - val_loss: 0.1099 - val_accuracy: 0.9688\n",
      "Epoch 12/24\n",
      "100/100 [==============================] - 2s 22ms/step - loss: 0.0766 - accuracy: 0.9773 - val_loss: 0.1132 - val_accuracy: 0.9700\n",
      "Epoch 13/24\n",
      "100/100 [==============================] - 2s 22ms/step - loss: 0.0687 - accuracy: 0.9793 - val_loss: 0.0999 - val_accuracy: 0.9713\n",
      "Epoch 14/24\n",
      "100/100 [==============================] - 2s 23ms/step - loss: 0.0631 - accuracy: 0.9815 - val_loss: 0.0932 - val_accuracy: 0.9744\n",
      "Epoch 15/24\n",
      "100/100 [==============================] - 2s 23ms/step - loss: 0.0552 - accuracy: 0.9829 - val_loss: 0.0984 - val_accuracy: 0.9722\n",
      "Epoch 16/24\n",
      "100/100 [==============================] - 2s 22ms/step - loss: 0.0541 - accuracy: 0.9834 - val_loss: 0.1182 - val_accuracy: 0.9674\n",
      "Epoch 17/24\n",
      "100/100 [==============================] - 2s 22ms/step - loss: 0.0516 - accuracy: 0.9840 - val_loss: 0.1010 - val_accuracy: 0.9733\n",
      "Epoch 18/24\n",
      "100/100 [==============================] - 2s 22ms/step - loss: 0.0427 - accuracy: 0.9869 - val_loss: 0.0942 - val_accuracy: 0.9736\n",
      "Epoch 19/24\n",
      "100/100 [==============================] - 2s 22ms/step - loss: 0.0351 - accuracy: 0.9896 - val_loss: 0.0977 - val_accuracy: 0.9733\n",
      "Epoch 20/24\n",
      "100/100 [==============================] - 2s 22ms/step - loss: 0.0311 - accuracy: 0.9907 - val_loss: 0.0899 - val_accuracy: 0.9761\n",
      "Epoch 21/24\n",
      "100/100 [==============================] - 2s 22ms/step - loss: 0.0293 - accuracy: 0.9912 - val_loss: 0.0991 - val_accuracy: 0.9735\n",
      "Epoch 22/24\n",
      "100/100 [==============================] - 2s 23ms/step - loss: 0.0258 - accuracy: 0.9923 - val_loss: 0.0955 - val_accuracy: 0.9760\n",
      "Epoch 23/24\n",
      "100/100 [==============================] - 2s 22ms/step - loss: 0.0235 - accuracy: 0.9931 - val_loss: 0.0918 - val_accuracy: 0.9771\n",
      "Epoch 24/24\n",
      "100/100 [==============================] - 2s 22ms/step - loss: 0.0211 - accuracy: 0.9936 - val_loss: 0.0902 - val_accuracy: 0.9782\n",
      "Listo!\n",
      "Precisión de validación actual: 97.82%\n",
      "Tiempo de entrenamiento: 56.46 segundos\n",
      "Entrenando modelo con TAMANIO_TANDA=450, TAMANIO_CAPA_ESCONDIDA=704, TASA_APRENDIZAJE=0.000857375, NUMERO_EPOCAS=26, NUMERO_CAPAS=5...\n",
      "Epoch 1/26\n",
      "112/112 [==============================] - 4s 31ms/step - loss: 1.4916 - accuracy: 0.4684 - val_loss: 0.5957 - val_accuracy: 0.8105\n",
      "Epoch 2/26\n",
      "112/112 [==============================] - 3s 30ms/step - loss: 0.4777 - accuracy: 0.8575 - val_loss: 0.3559 - val_accuracy: 0.8937\n",
      "Epoch 3/26\n",
      "112/112 [==============================] - 3s 30ms/step - loss: 0.3436 - accuracy: 0.8984 - val_loss: 0.2644 - val_accuracy: 0.9214\n",
      "Epoch 4/26\n",
      "112/112 [==============================] - 3s 30ms/step - loss: 0.2649 - accuracy: 0.9208 - val_loss: 0.2182 - val_accuracy: 0.9344\n",
      "Epoch 5/26\n",
      "112/112 [==============================] - 4s 31ms/step - loss: 0.2165 - accuracy: 0.9345 - val_loss: 0.2202 - val_accuracy: 0.9313\n",
      "Epoch 6/26\n",
      "112/112 [==============================] - 3s 29ms/step - loss: 0.1892 - accuracy: 0.9419 - val_loss: 0.1885 - val_accuracy: 0.9447\n",
      "Epoch 7/26\n",
      "112/112 [==============================] - 3s 29ms/step - loss: 0.1627 - accuracy: 0.9506 - val_loss: 0.1571 - val_accuracy: 0.9535\n",
      "Epoch 8/26\n",
      "112/112 [==============================] - 3s 30ms/step - loss: 0.1457 - accuracy: 0.9557 - val_loss: 0.1847 - val_accuracy: 0.9453\n",
      "Epoch 9/26\n",
      "112/112 [==============================] - 3s 29ms/step - loss: 0.1304 - accuracy: 0.9609 - val_loss: 0.1353 - val_accuracy: 0.9615\n",
      "Epoch 10/26\n",
      "112/112 [==============================] - 3s 30ms/step - loss: 0.1174 - accuracy: 0.9651 - val_loss: 0.1323 - val_accuracy: 0.9619\n",
      "Epoch 11/26\n",
      "112/112 [==============================] - 3s 29ms/step - loss: 0.1042 - accuracy: 0.9688 - val_loss: 0.1133 - val_accuracy: 0.9670\n",
      "Epoch 12/26\n",
      "112/112 [==============================] - 3s 29ms/step - loss: 0.0984 - accuracy: 0.9706 - val_loss: 0.1067 - val_accuracy: 0.9685\n",
      "Epoch 13/26\n",
      "112/112 [==============================] - 3s 29ms/step - loss: 0.0842 - accuracy: 0.9753 - val_loss: 0.1686 - val_accuracy: 0.9528\n",
      "Epoch 14/26\n",
      "112/112 [==============================] - 3s 29ms/step - loss: 0.0809 - accuracy: 0.9759 - val_loss: 0.1047 - val_accuracy: 0.9710\n",
      "Epoch 15/26\n",
      "112/112 [==============================] - 3s 29ms/step - loss: 0.0709 - accuracy: 0.9790 - val_loss: 0.1088 - val_accuracy: 0.9704\n",
      "Epoch 16/26\n",
      "112/112 [==============================] - 3s 29ms/step - loss: 0.0661 - accuracy: 0.9804 - val_loss: 0.1221 - val_accuracy: 0.9656\n",
      "Epoch 17/26\n",
      "112/112 [==============================] - 3s 29ms/step - loss: 0.0624 - accuracy: 0.9813 - val_loss: 0.1078 - val_accuracy: 0.9699\n",
      "Epoch 18/26\n",
      "112/112 [==============================] - 3s 29ms/step - loss: 0.0542 - accuracy: 0.9836 - val_loss: 0.1066 - val_accuracy: 0.9721\n",
      "Epoch 19/26\n",
      "112/112 [==============================] - 3s 29ms/step - loss: 0.0552 - accuracy: 0.9832 - val_loss: 0.1234 - val_accuracy: 0.9676\n",
      "Epoch 20/26\n",
      "112/112 [==============================] - 3s 29ms/step - loss: 0.0452 - accuracy: 0.9870 - val_loss: 0.1055 - val_accuracy: 0.9708\n",
      "Epoch 21/26\n",
      "112/112 [==============================] - 3s 29ms/step - loss: 0.0466 - accuracy: 0.9856 - val_loss: 0.1089 - val_accuracy: 0.9721\n",
      "Epoch 22/26\n",
      "112/112 [==============================] - 3s 29ms/step - loss: 0.0367 - accuracy: 0.9888 - val_loss: 0.1002 - val_accuracy: 0.9749\n",
      "Epoch 23/26\n",
      "112/112 [==============================] - 3s 30ms/step - loss: 0.0372 - accuracy: 0.9889 - val_loss: 0.1039 - val_accuracy: 0.9731\n",
      "Epoch 24/26\n",
      "112/112 [==============================] - 3s 29ms/step - loss: 0.0325 - accuracy: 0.9897 - val_loss: 0.0937 - val_accuracy: 0.9759\n",
      "Epoch 25/26\n",
      "112/112 [==============================] - 3s 29ms/step - loss: 0.0255 - accuracy: 0.9926 - val_loss: 0.0996 - val_accuracy: 0.9745\n",
      "Epoch 26/26\n",
      "112/112 [==============================] - 3s 30ms/step - loss: 0.0341 - accuracy: 0.9895 - val_loss: 0.1296 - val_accuracy: 0.9679\n",
      "Listo!\n",
      "Precisión de validación actual: 96.79%\n",
      "Tiempo de entrenamiento: 88.28 segundos\n",
      "Entrenando modelo con TAMANIO_TANDA=400, TAMANIO_CAPA_ESCONDIDA=768, TASA_APRENDIZAJE=0.0008145062499999999, NUMERO_EPOCAS=28, NUMERO_CAPAS=6...\n",
      "Epoch 1/28\n",
      "125/125 [==============================] - 4s 28ms/step - loss: 1.8939 - accuracy: 0.2657 - val_loss: 1.0321 - val_accuracy: 0.6283\n",
      "Epoch 2/28\n",
      "125/125 [==============================] - 3s 27ms/step - loss: 0.7374 - accuracy: 0.7585 - val_loss: 0.4611 - val_accuracy: 0.8639\n",
      "Epoch 3/28\n",
      "125/125 [==============================] - 3s 27ms/step - loss: 0.4421 - accuracy: 0.8712 - val_loss: 0.3407 - val_accuracy: 0.8980\n",
      "Epoch 4/28\n",
      "125/125 [==============================] - 3s 26ms/step - loss: 0.3247 - accuracy: 0.9071 - val_loss: 0.2543 - val_accuracy: 0.9277\n",
      "Epoch 5/28\n",
      "125/125 [==============================] - 3s 26ms/step - loss: 0.2558 - accuracy: 0.9262 - val_loss: 0.2271 - val_accuracy: 0.9327\n",
      "Epoch 6/28\n",
      "125/125 [==============================] - 3s 27ms/step - loss: 0.2095 - accuracy: 0.9382 - val_loss: 0.1829 - val_accuracy: 0.9451\n",
      "Epoch 7/28\n",
      "125/125 [==============================] - 3s 27ms/step - loss: 0.1769 - accuracy: 0.9475 - val_loss: 0.1697 - val_accuracy: 0.9524\n",
      "Epoch 8/28\n",
      "125/125 [==============================] - 3s 27ms/step - loss: 0.1598 - accuracy: 0.9517 - val_loss: 0.1596 - val_accuracy: 0.9541\n",
      "Epoch 9/28\n",
      "125/125 [==============================] - 4s 27ms/step - loss: 0.1382 - accuracy: 0.9587 - val_loss: 0.1361 - val_accuracy: 0.9611\n",
      "Epoch 10/28\n",
      "125/125 [==============================] - 3s 26ms/step - loss: 0.1272 - accuracy: 0.9619 - val_loss: 0.1364 - val_accuracy: 0.9604\n",
      "Epoch 11/28\n",
      "125/125 [==============================] - 3s 27ms/step - loss: 0.1168 - accuracy: 0.9654 - val_loss: 0.1320 - val_accuracy: 0.9603\n",
      "Epoch 12/28\n",
      "125/125 [==============================] - 3s 26ms/step - loss: 0.1026 - accuracy: 0.9694 - val_loss: 0.1293 - val_accuracy: 0.9635\n",
      "Epoch 13/28\n",
      "125/125 [==============================] - 3s 27ms/step - loss: 0.0953 - accuracy: 0.9722 - val_loss: 0.1166 - val_accuracy: 0.9676\n",
      "Epoch 14/28\n",
      "125/125 [==============================] - 4s 28ms/step - loss: 0.0871 - accuracy: 0.9738 - val_loss: 0.1198 - val_accuracy: 0.9676\n",
      "Epoch 15/28\n",
      "125/125 [==============================] - 4s 28ms/step - loss: 0.0821 - accuracy: 0.9757 - val_loss: 0.1194 - val_accuracy: 0.9651\n",
      "Epoch 16/28\n",
      "125/125 [==============================] - 4s 29ms/step - loss: 0.0730 - accuracy: 0.9781 - val_loss: 0.1239 - val_accuracy: 0.9641\n",
      "Epoch 17/28\n",
      "125/125 [==============================] - 4s 29ms/step - loss: 0.0661 - accuracy: 0.9803 - val_loss: 0.1176 - val_accuracy: 0.9675\n",
      "Epoch 18/28\n",
      "125/125 [==============================] - 4s 28ms/step - loss: 0.0575 - accuracy: 0.9830 - val_loss: 0.1038 - val_accuracy: 0.9731\n",
      "Epoch 19/28\n",
      "125/125 [==============================] - 4s 28ms/step - loss: 0.0596 - accuracy: 0.9817 - val_loss: 0.1144 - val_accuracy: 0.9709\n",
      "Epoch 20/28\n",
      "125/125 [==============================] - 4s 28ms/step - loss: 0.0561 - accuracy: 0.9832 - val_loss: 0.1155 - val_accuracy: 0.9694\n",
      "Epoch 21/28\n",
      "125/125 [==============================] - 3s 27ms/step - loss: 0.0442 - accuracy: 0.9870 - val_loss: 0.1051 - val_accuracy: 0.9729\n",
      "Epoch 22/28\n",
      "125/125 [==============================] - 4s 28ms/step - loss: 0.0404 - accuracy: 0.9880 - val_loss: 0.1110 - val_accuracy: 0.9741\n",
      "Epoch 23/28\n",
      "125/125 [==============================] - 4s 28ms/step - loss: 0.0413 - accuracy: 0.9875 - val_loss: 0.1019 - val_accuracy: 0.9738\n",
      "Epoch 24/28\n",
      "125/125 [==============================] - 3s 26ms/step - loss: 0.0344 - accuracy: 0.9892 - val_loss: 0.1088 - val_accuracy: 0.9737\n",
      "Epoch 25/28\n",
      "125/125 [==============================] - 3s 27ms/step - loss: 0.0339 - accuracy: 0.9900 - val_loss: 0.1105 - val_accuracy: 0.9731\n",
      "Epoch 26/28\n",
      "125/125 [==============================] - 3s 27ms/step - loss: 0.0323 - accuracy: 0.9899 - val_loss: 0.1424 - val_accuracy: 0.9669\n",
      "Epoch 27/28\n",
      "125/125 [==============================] - 3s 26ms/step - loss: 0.0307 - accuracy: 0.9905 - val_loss: 0.1068 - val_accuracy: 0.9746\n",
      "Epoch 28/28\n",
      "125/125 [==============================] - 3s 26ms/step - loss: 0.0321 - accuracy: 0.9901 - val_loss: 0.1068 - val_accuracy: 0.9759\n",
      "Listo!\n",
      "Precisión de validación actual: 97.59%\n",
      "Tiempo de entrenamiento: 98.09 segundos\n",
      "Entrenando modelo con TAMANIO_TANDA=350, TAMANIO_CAPA_ESCONDIDA=832, TASA_APRENDIZAJE=0.0007737809374999998, NUMERO_EPOCAS=30, NUMERO_CAPAS=7...\n",
      "Epoch 1/30\n",
      "143/143 [==============================] - 5s 33ms/step - loss: 2.2871 - accuracy: 0.1161 - val_loss: 1.8147 - val_accuracy: 0.2169\n",
      "Epoch 2/30\n",
      "143/143 [==============================] - 5s 31ms/step - loss: 1.0622 - accuracy: 0.6080 - val_loss: 0.7187 - val_accuracy: 0.7644\n",
      "Epoch 3/30\n",
      "143/143 [==============================] - 5s 31ms/step - loss: 0.5604 - accuracy: 0.8327 - val_loss: 0.4309 - val_accuracy: 0.8739\n",
      "Epoch 4/30\n",
      "143/143 [==============================] - 5s 31ms/step - loss: 0.4092 - accuracy: 0.8837 - val_loss: 0.3218 - val_accuracy: 0.9060\n",
      "Epoch 5/30\n",
      "143/143 [==============================] - 5s 33ms/step - loss: 0.3343 - accuracy: 0.9041 - val_loss: 0.2938 - val_accuracy: 0.9154\n",
      "Epoch 6/30\n",
      "143/143 [==============================] - 5s 34ms/step - loss: 0.2753 - accuracy: 0.9198 - val_loss: 0.2422 - val_accuracy: 0.9270\n",
      "Epoch 7/30\n",
      "143/143 [==============================] - 5s 34ms/step - loss: 0.2495 - accuracy: 0.9277 - val_loss: 0.1937 - val_accuracy: 0.9403\n",
      "Epoch 8/30\n",
      "143/143 [==============================] - 5s 33ms/step - loss: 0.1984 - accuracy: 0.9416 - val_loss: 0.1720 - val_accuracy: 0.9522\n",
      "Epoch 9/30\n",
      "143/143 [==============================] - 5s 32ms/step - loss: 0.1778 - accuracy: 0.9476 - val_loss: 0.1739 - val_accuracy: 0.9487\n",
      "Epoch 10/30\n",
      "143/143 [==============================] - 5s 32ms/step - loss: 0.1531 - accuracy: 0.9551 - val_loss: 0.1419 - val_accuracy: 0.9568\n",
      "Epoch 11/30\n",
      "143/143 [==============================] - 5s 35ms/step - loss: 0.1311 - accuracy: 0.9608 - val_loss: 0.1385 - val_accuracy: 0.9611\n",
      "Epoch 12/30\n",
      "143/143 [==============================] - 5s 33ms/step - loss: 0.1145 - accuracy: 0.9664 - val_loss: 0.1511 - val_accuracy: 0.9564\n",
      "Epoch 13/30\n",
      "143/143 [==============================] - 5s 34ms/step - loss: 0.1098 - accuracy: 0.9675 - val_loss: 0.1211 - val_accuracy: 0.9669\n",
      "Epoch 14/30\n",
      "143/143 [==============================] - 5s 34ms/step - loss: 0.0991 - accuracy: 0.9710 - val_loss: 0.1306 - val_accuracy: 0.9634\n",
      "Epoch 15/30\n",
      "143/143 [==============================] - 6s 38ms/step - loss: 0.0841 - accuracy: 0.9756 - val_loss: 0.1326 - val_accuracy: 0.9631\n",
      "Epoch 16/30\n",
      "143/143 [==============================] - 5s 36ms/step - loss: 0.0795 - accuracy: 0.9765 - val_loss: 0.1165 - val_accuracy: 0.9677\n",
      "Epoch 17/30\n",
      "143/143 [==============================] - 5s 34ms/step - loss: 0.0742 - accuracy: 0.9781 - val_loss: 0.1193 - val_accuracy: 0.9650\n",
      "Epoch 18/30\n",
      "143/143 [==============================] - 5s 33ms/step - loss: 0.0655 - accuracy: 0.9804 - val_loss: 0.1130 - val_accuracy: 0.9685\n",
      "Epoch 19/30\n",
      "143/143 [==============================] - 5s 34ms/step - loss: 0.0585 - accuracy: 0.9830 - val_loss: 0.1179 - val_accuracy: 0.9684\n",
      "Epoch 20/30\n",
      "143/143 [==============================] - 5s 34ms/step - loss: 0.0569 - accuracy: 0.9831 - val_loss: 0.1094 - val_accuracy: 0.9719\n",
      "Epoch 21/30\n",
      "143/143 [==============================] - 5s 33ms/step - loss: 0.0533 - accuracy: 0.9841 - val_loss: 0.1076 - val_accuracy: 0.9725\n",
      "Epoch 22/30\n",
      "143/143 [==============================] - 5s 35ms/step - loss: 0.0461 - accuracy: 0.9861 - val_loss: 0.1190 - val_accuracy: 0.9688\n",
      "Epoch 23/30\n",
      "143/143 [==============================] - 5s 36ms/step - loss: 0.0416 - accuracy: 0.9876 - val_loss: 0.1072 - val_accuracy: 0.9723\n",
      "Epoch 24/30\n",
      "143/143 [==============================] - 5s 37ms/step - loss: 0.0367 - accuracy: 0.9894 - val_loss: 0.1061 - val_accuracy: 0.9743\n",
      "Epoch 25/30\n",
      "143/143 [==============================] - 5s 36ms/step - loss: 0.0343 - accuracy: 0.9898 - val_loss: 0.1146 - val_accuracy: 0.9729\n",
      "Epoch 26/30\n",
      "143/143 [==============================] - 5s 33ms/step - loss: 0.0347 - accuracy: 0.9897 - val_loss: 0.1047 - val_accuracy: 0.9757\n",
      "Epoch 27/30\n",
      "143/143 [==============================] - 5s 35ms/step - loss: 0.0313 - accuracy: 0.9907 - val_loss: 0.1195 - val_accuracy: 0.9732\n",
      "Epoch 28/30\n",
      "143/143 [==============================] - 5s 31ms/step - loss: 0.0306 - accuracy: 0.9908 - val_loss: 0.1175 - val_accuracy: 0.9727\n",
      "Epoch 29/30\n",
      "143/143 [==============================] - 5s 32ms/step - loss: 0.0278 - accuracy: 0.9918 - val_loss: 0.1101 - val_accuracy: 0.9753\n",
      "Epoch 30/30\n",
      "143/143 [==============================] - 5s 33ms/step - loss: 0.0241 - accuracy: 0.9927 - val_loss: 0.1191 - val_accuracy: 0.9734\n",
      "Listo!\n",
      "Precisión de validación actual: 97.34%\n",
      "Tiempo de entrenamiento: 147.38 segundos\n",
      "Entrenando modelo con TAMANIO_TANDA=300, TAMANIO_CAPA_ESCONDIDA=896, TASA_APRENDIZAJE=0.0007350918906249997, NUMERO_EPOCAS=32, NUMERO_CAPAS=8...\n",
      "Epoch 1/32\n",
      "167/167 [==============================] - 8s 42ms/step - loss: 2.3259 - accuracy: 0.1026 - val_loss: 2.3115 - val_accuracy: 0.1064\n",
      "Epoch 2/32\n",
      "167/167 [==============================] - 7s 40ms/step - loss: 2.3108 - accuracy: 0.1073 - val_loss: 2.3110 - val_accuracy: 0.1064\n",
      "Epoch 3/32\n",
      "167/167 [==============================] - 7s 39ms/step - loss: 1.9373 - accuracy: 0.2270 - val_loss: 1.5158 - val_accuracy: 0.4022\n",
      "Epoch 4/32\n",
      "167/167 [==============================] - 7s 41ms/step - loss: 1.1426 - accuracy: 0.5723 - val_loss: 0.8242 - val_accuracy: 0.7155\n",
      "Epoch 5/32\n",
      "167/167 [==============================] - 7s 40ms/step - loss: 0.6659 - accuracy: 0.7781 - val_loss: 0.4583 - val_accuracy: 0.8745\n",
      "Epoch 6/32\n",
      "167/167 [==============================] - 7s 39ms/step - loss: 0.4060 - accuracy: 0.8895 - val_loss: 0.3357 - val_accuracy: 0.9111\n",
      "Epoch 7/32\n",
      "167/167 [==============================] - 6s 37ms/step - loss: 0.3044 - accuracy: 0.9185 - val_loss: 0.2522 - val_accuracy: 0.9306\n",
      "Epoch 8/32\n",
      "167/167 [==============================] - 7s 39ms/step - loss: 0.2370 - accuracy: 0.9346 - val_loss: 0.1908 - val_accuracy: 0.9451\n",
      "Epoch 9/32\n",
      "167/167 [==============================] - 6s 36ms/step - loss: 0.1989 - accuracy: 0.9451 - val_loss: 0.1757 - val_accuracy: 0.9500\n",
      "Epoch 10/32\n",
      "167/167 [==============================] - 6s 38ms/step - loss: 0.1692 - accuracy: 0.9528 - val_loss: 0.1827 - val_accuracy: 0.9481\n",
      "Epoch 11/32\n",
      "167/167 [==============================] - 7s 40ms/step - loss: 0.1576 - accuracy: 0.9548 - val_loss: 0.1458 - val_accuracy: 0.9571\n",
      "Epoch 12/32\n",
      "167/167 [==============================] - 7s 40ms/step - loss: 0.1352 - accuracy: 0.9612 - val_loss: 0.1336 - val_accuracy: 0.9619\n",
      "Epoch 13/32\n",
      "167/167 [==============================] - 7s 39ms/step - loss: 0.1200 - accuracy: 0.9660 - val_loss: 0.1242 - val_accuracy: 0.9659\n",
      "Epoch 14/32\n",
      "167/167 [==============================] - 7s 42ms/step - loss: 0.1097 - accuracy: 0.9684 - val_loss: 0.1381 - val_accuracy: 0.9613\n",
      "Epoch 15/32\n",
      "167/167 [==============================] - 7s 42ms/step - loss: 0.0964 - accuracy: 0.9723 - val_loss: 0.1261 - val_accuracy: 0.9647\n",
      "Epoch 16/32\n",
      "154/167 [==========================>...] - ETA: 0s - loss: 0.0935 - accuracy: 0.9732"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 59\u001b[0m\n\u001b[0;32m     56\u001b[0m precision_validacion_actual \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m precision_validacion_actual \u001b[38;5;241m<\u001b[39m precision_objetivo:\n\u001b[1;32m---> 59\u001b[0m     precision_validacion_actual, tiempo_entrenamiento \u001b[38;5;241m=\u001b[39m \u001b[43mentrenar_y_evaluar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTAMANIO_TANDA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTAMANIO_CAPA_ESCONDIDA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTASA_APRENDIZAJE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNUMERO_EPOCAS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNUMERO_CAPAS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;66;03m# Ajustar parámetros si no se alcanza la precisión objetivo\u001b[39;00m\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m precision_validacion_actual \u001b[38;5;241m<\u001b[39m precision_objetivo:\n",
      "Cell \u001b[1;32mIn[36], line 37\u001b[0m, in \u001b[0;36mentrenar_y_evaluar\u001b[1;34m(TAMANIO_TANDA, TAMANIO_CAPA_ESCONDIDA, TASA_APRENDIZAJE, NUMERO_EPOCAS, NUMERO_CAPAS)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEntrenando modelo con TAMANIO_TANDA=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mTAMANIO_TANDA\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, TAMANIO_CAPA_ESCONDIDA=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mTAMANIO_CAPA_ESCONDIDA\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, TASA_APRENDIZAJE=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mTASA_APRENDIZAJE\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, NUMERO_EPOCAS=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mNUMERO_EPOCAS\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, NUMERO_CAPAS=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mNUMERO_CAPAS\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     36\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m---> 37\u001b[0m historia \u001b[38;5;241m=\u001b[39m \u001b[43mmodelo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdatos_entreno\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNUMERO_EPOCAS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatos_validacion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     39\u001b[0m tiempo_entrenamiento \u001b[38;5;241m=\u001b[39m end \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[1;32mc:\\Users\\caste\\anaconda3\\envs\\base9\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\caste\\anaconda3\\envs\\base9\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\caste\\anaconda3\\envs\\base9\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\caste\\anaconda3\\envs\\base9\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\caste\\anaconda3\\envs\\base9\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\caste\\anaconda3\\envs\\base9\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\caste\\anaconda3\\envs\\base9\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\caste\\anaconda3\\envs\\base9\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\caste\\anaconda3\\envs\\base9\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import time\n",
    "\n",
    "# Función para entrenar y evaluar el modelo\n",
    "def entrenar_y_evaluar(TAMANIO_TANDA, TAMANIO_CAPA_ESCONDIDA, TASA_APRENDIZAJE, NUMERO_EPOCAS, NUMERO_CAPAS):\n",
    "    # Reestablecer los conjuntos de datos\n",
    "    datos_entreno = tf.data.Dataset.from_tensor_slices((X_entreno, y_entreno))\n",
    "    datos_validacion = tf.data.Dataset.from_tensor_slices((X_validacion, y_validacion))\n",
    "    datos_prueba = tf.data.Dataset.from_tensor_slices((X_prueba, y_prueba))\n",
    "\n",
    "    # Dividir en tandas los conjuntos de datos\n",
    "    datos_entreno = datos_entreno.shuffle(buffer_size=num_obs_entreno).batch(TAMANIO_TANDA)  # Barajear datos de entrenamiento\n",
    "    datos_validacion = datos_validacion.batch(TAMANIO_TANDA)\n",
    "    datos_prueba = datos_prueba.batch(TAMANIO_TANDA)\n",
    "\n",
    "    # Definimos la nueva estructura del modelo\n",
    "    modelo = tf.keras.Sequential()\n",
    "    modelo.add(tf.keras.Input(shape=(28, 28)))  # capas de entrada\n",
    "    modelo.add(tf.keras.layers.Flatten())\n",
    "    \n",
    "    # Agregar capas ocultas\n",
    "    for _ in range(NUMERO_CAPAS):\n",
    "        modelo.add(tf.keras.layers.Dense(TAMANIO_CAPA_ESCONDIDA, activation='sigmoid'))\n",
    "    \n",
    "    modelo.add(tf.keras.layers.Dense(tamanio_salida, activation='softmax'))  # capa salida\n",
    "\n",
    "    # Crear el optimizador con la tasa de aprendizaje especificada\n",
    "    optimizador = Adam(learning_rate=TASA_APRENDIZAJE)\n",
    "\n",
    "    # Compilamos el modelo\n",
    "    modelo.compile(optimizer=optimizador, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Entrenar el modelo\n",
    "    print(f\"Entrenando modelo con TAMANIO_TANDA={TAMANIO_TANDA}, TAMANIO_CAPA_ESCONDIDA={TAMANIO_CAPA_ESCONDIDA}, TASA_APRENDIZAJE={TASA_APRENDIZAJE}, NUMERO_EPOCAS={NUMERO_EPOCAS}, NUMERO_CAPAS={NUMERO_CAPAS}...\")\n",
    "    start = time.time()\n",
    "    historia = modelo.fit(datos_entreno, epochs=NUMERO_EPOCAS, validation_data=datos_validacion, verbose=1)\n",
    "    end = time.time()\n",
    "    tiempo_entrenamiento = end - start\n",
    "    print(\"Listo!\")\n",
    "\n",
    "    # Obtener la precisión de validación final\n",
    "    precision_validacion = historia.history['val_accuracy'][-1]\n",
    "\n",
    "    return precision_validacion, tiempo_entrenamiento\n",
    "\n",
    "# Parámetros iniciales\n",
    "TAMANIO_TANDA = 600\n",
    "TAMANIO_CAPA_ESCONDIDA = 512\n",
    "TASA_APRENDIZAJE = 0.001\n",
    "NUMERO_EPOCAS = 20\n",
    "NUMERO_CAPAS = 2\n",
    "\n",
    "# Bucle para ajustar los parámetros\n",
    "precision_objetivo = 0.985\n",
    "precision_validacion_actual = 0.0\n",
    "\n",
    "while precision_validacion_actual < precision_objetivo:\n",
    "    precision_validacion_actual, tiempo_entrenamiento = entrenar_y_evaluar(TAMANIO_TANDA, TAMANIO_CAPA_ESCONDIDA, TASA_APRENDIZAJE, NUMERO_EPOCAS, NUMERO_CAPAS)\n",
    "    \n",
    "    # Ajustar parámetros si no se alcanza la precisión objetivo\n",
    "    if precision_validacion_actual < precision_objetivo:\n",
    "        NUMERO_CAPAS += 1  # Aumentar el número de capas ocultas\n",
    "        TAMANIO_CAPA_ESCONDIDA += 64  # Aumentar el tamaño de la capa oculta\n",
    "        TASA_APRENDIZAJE *= 0.95  # Reducir la tasa de aprendizaje\n",
    "        NUMERO_EPOCAS += 2  # Aumentar el número de épocas\n",
    "        TAMANIO_TANDA = max(100, TAMANIO_TANDA - 50)  # Reducir el tamaño de la tanda, mínimo 100\n",
    "\n",
    "    print(f\"Precisión de validación actual: {precision_validacion_actual * 100:.2f}%\")\n",
    "    print(f\"Tiempo de entrenamiento: {tiempo_entrenamiento:.2f} segundos\")\n",
    "\n",
    "print(\"¡Precisión objetivo alcanzada!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parámetros finales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo con TAMANIO_TANDA=200, TAMANIO_CAPA_ESCONDIDA=1024, TASA_APRENDIZAJE=0.0006561, NUMERO_EPOCAS=50...\n",
      "Epoch 1/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 42ms/step - accuracy: 0.6190 - loss: 1.2383 - val_accuracy: 0.9119 - val_loss: 0.2949\n",
      "Epoch 2/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 40ms/step - accuracy: 0.9115 - loss: 0.2986 - val_accuracy: 0.9282 - val_loss: 0.2471\n",
      "Epoch 3/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.9293 - loss: 0.2432 - val_accuracy: 0.9375 - val_loss: 0.2153\n",
      "Epoch 4/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 41ms/step - accuracy: 0.9392 - loss: 0.2058 - val_accuracy: 0.9485 - val_loss: 0.1783\n",
      "Epoch 5/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 41ms/step - accuracy: 0.9452 - loss: 0.1783 - val_accuracy: 0.9567 - val_loss: 0.1536\n",
      "Epoch 6/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - accuracy: 0.9578 - loss: 0.1430 - val_accuracy: 0.9583 - val_loss: 0.1429\n",
      "Epoch 7/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - accuracy: 0.9605 - loss: 0.1308 - val_accuracy: 0.9621 - val_loss: 0.1322\n",
      "Epoch 8/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 40ms/step - accuracy: 0.9659 - loss: 0.1127 - val_accuracy: 0.9664 - val_loss: 0.1124\n",
      "Epoch 9/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - accuracy: 0.9727 - loss: 0.0931 - val_accuracy: 0.9698 - val_loss: 0.1051\n",
      "Epoch 10/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 40ms/step - accuracy: 0.9771 - loss: 0.0791 - val_accuracy: 0.9690 - val_loss: 0.1032\n",
      "Epoch 11/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 41ms/step - accuracy: 0.9781 - loss: 0.0730 - val_accuracy: 0.9716 - val_loss: 0.1002\n",
      "Epoch 12/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 40ms/step - accuracy: 0.9827 - loss: 0.0588 - val_accuracy: 0.9744 - val_loss: 0.0898\n",
      "Epoch 13/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 40ms/step - accuracy: 0.9858 - loss: 0.0494 - val_accuracy: 0.9738 - val_loss: 0.0897\n",
      "Epoch 14/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 40ms/step - accuracy: 0.9875 - loss: 0.0432 - val_accuracy: 0.9736 - val_loss: 0.0891\n",
      "Epoch 15/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.9885 - loss: 0.0384 - val_accuracy: 0.9744 - val_loss: 0.0874\n",
      "Epoch 16/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.9909 - loss: 0.0320 - val_accuracy: 0.9767 - val_loss: 0.0794\n",
      "Epoch 17/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 41ms/step - accuracy: 0.9922 - loss: 0.0266 - val_accuracy: 0.9767 - val_loss: 0.0802\n",
      "Epoch 18/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 40ms/step - accuracy: 0.9932 - loss: 0.0246 - val_accuracy: 0.9784 - val_loss: 0.0780\n",
      "Epoch 19/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 40ms/step - accuracy: 0.9957 - loss: 0.0178 - val_accuracy: 0.9788 - val_loss: 0.0784\n",
      "Epoch 20/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 41ms/step - accuracy: 0.9953 - loss: 0.0170 - val_accuracy: 0.9766 - val_loss: 0.0872\n",
      "Epoch 21/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 41ms/step - accuracy: 0.9963 - loss: 0.0142 - val_accuracy: 0.9776 - val_loss: 0.0859\n",
      "Epoch 22/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 41ms/step - accuracy: 0.9970 - loss: 0.0116 - val_accuracy: 0.9788 - val_loss: 0.0803\n",
      "Epoch 23/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 41ms/step - accuracy: 0.9974 - loss: 0.0108 - val_accuracy: 0.9800 - val_loss: 0.0823\n",
      "Epoch 24/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 41ms/step - accuracy: 0.9978 - loss: 0.0087 - val_accuracy: 0.9798 - val_loss: 0.0845\n",
      "Epoch 25/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 41ms/step - accuracy: 0.9985 - loss: 0.0074 - val_accuracy: 0.9799 - val_loss: 0.0821\n",
      "Epoch 26/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 41ms/step - accuracy: 0.9987 - loss: 0.0061 - val_accuracy: 0.9805 - val_loss: 0.0870\n",
      "Epoch 27/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 41ms/step - accuracy: 0.9988 - loss: 0.0052 - val_accuracy: 0.9778 - val_loss: 0.0959\n",
      "Epoch 28/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 41ms/step - accuracy: 0.9973 - loss: 0.0086 - val_accuracy: 0.9794 - val_loss: 0.0931\n",
      "Epoch 29/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 41ms/step - accuracy: 0.9990 - loss: 0.0040 - val_accuracy: 0.9770 - val_loss: 0.1047\n",
      "Epoch 30/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 46ms/step - accuracy: 0.9991 - loss: 0.0039 - val_accuracy: 0.9812 - val_loss: 0.0892\n",
      "Epoch 31/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 40ms/step - accuracy: 0.9998 - loss: 0.0019 - val_accuracy: 0.9813 - val_loss: 0.0868\n",
      "Epoch 32/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - accuracy: 0.9998 - loss: 0.0016 - val_accuracy: 0.9797 - val_loss: 0.0962\n",
      "Epoch 33/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 40ms/step - accuracy: 0.9997 - loss: 0.0017 - val_accuracy: 0.9797 - val_loss: 0.1088\n",
      "Epoch 34/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 40ms/step - accuracy: 0.9961 - loss: 0.0102 - val_accuracy: 0.9759 - val_loss: 0.1142\n",
      "Epoch 35/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 40ms/step - accuracy: 0.9992 - loss: 0.0031 - val_accuracy: 0.9801 - val_loss: 0.0955\n",
      "Epoch 36/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - accuracy: 0.9997 - loss: 0.0016 - val_accuracy: 0.9817 - val_loss: 0.0919\n",
      "Epoch 37/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 4.9448e-04 - val_accuracy: 0.9821 - val_loss: 0.0929\n",
      "Epoch 38/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 40ms/step - accuracy: 0.9999 - loss: 6.1858e-04 - val_accuracy: 0.9817 - val_loss: 0.0951\n",
      "Epoch 39/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 41ms/step - accuracy: 0.9994 - loss: 0.0024 - val_accuracy: 0.9793 - val_loss: 0.1020\n",
      "Epoch 40/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 40ms/step - accuracy: 0.9997 - loss: 0.0015 - val_accuracy: 0.9764 - val_loss: 0.1319\n",
      "Epoch 41/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - accuracy: 0.9971 - loss: 0.0077 - val_accuracy: 0.9760 - val_loss: 0.1335\n",
      "Epoch 42/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 40ms/step - accuracy: 0.9979 - loss: 0.0060 - val_accuracy: 0.9801 - val_loss: 0.1102\n",
      "Epoch 43/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - accuracy: 0.9995 - loss: 0.0022 - val_accuracy: 0.9807 - val_loss: 0.1011\n",
      "Epoch 44/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 41ms/step - accuracy: 0.9996 - loss: 0.0014 - val_accuracy: 0.9818 - val_loss: 0.1015\n",
      "Epoch 45/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 3.0431e-04 - val_accuracy: 0.9820 - val_loss: 0.1008\n",
      "Epoch 46/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 1.4168e-04 - val_accuracy: 0.9826 - val_loss: 0.1007\n",
      "Epoch 47/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 1.4786e-04 - val_accuracy: 0.9826 - val_loss: 0.1005\n",
      "Epoch 48/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 1.0094e-04 - val_accuracy: 0.9823 - val_loss: 0.1017\n",
      "Epoch 49/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 8.2288e-05 - val_accuracy: 0.9825 - val_loss: 0.1023\n",
      "Epoch 50/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 9.5124e-05 - val_accuracy: 0.9825 - val_loss: 0.1019\n",
      "Listo!\n",
      "Evaluando modelo...\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9745 - loss: 0.1800\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tasa de aprendizaje</th>\n",
       "      <th>Precisión de entrenamiento</th>\n",
       "      <th>Precisión de prueba</th>\n",
       "      <th>Precisión de validación</th>\n",
       "      <th>Tiempo de entrenamiento (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.02</td>\n",
       "      <td>100.00%</td>\n",
       "      <td>97.91%</td>\n",
       "      <td>98.25%</td>\n",
       "      <td>510.80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Tasa de aprendizaje Precisión de entrenamiento Precisión de prueba  \\\n",
       "0                 0.02                    100.00%              97.91%   \n",
       "\n",
       "  Precisión de validación Tiempo de entrenamiento (s)  \n",
       "0                  98.25%                      510.80  "
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TAMANIO_TANDA = 200\n",
    "TAMANIO_CAPA_ESCONDIDA = 1024\n",
    "TASA_APRENDIZAJE = 0.0006561\n",
    "NUMERO_EPOCAS = 50\n",
    "\n",
    "# Reestablecer los conjuntos de datos\n",
    "datos_entreno = tf.data.Dataset.from_tensor_slices((X_entreno, y_entreno))\n",
    "datos_validacion = tf.data.Dataset.from_tensor_slices((X_validacion, y_validacion))\n",
    "datos_prueba = tf.data.Dataset.from_tensor_slices((X_prueba, y_prueba))\n",
    "\n",
    "# Dividir en tandas los conjuntos de datos\n",
    "datos_entreno = datos_entreno.shuffle(buffer_size=num_obs_entreno).batch(TAMANIO_TANDA)  # Barajear datos de entrenamiento\n",
    "datos_validacion = datos_validacion.batch(TAMANIO_TANDA)\n",
    "datos_prueba = datos_prueba.batch(TAMANIO_TANDA)\n",
    "\n",
    "# Definimos la nueva estructura del modelo\n",
    "modelo = tf.keras.Sequential([\n",
    "    tf.keras.Input(shape=(28, 28)),  # capas de entrada\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(TAMANIO_CAPA_ESCONDIDA, activation='sigmoid'),  # 1era capa escondida\n",
    "    tf.keras.layers.Dense(TAMANIO_CAPA_ESCONDIDA, activation='sigmoid'),  # 2nda capa escondida\n",
    "    tf.keras.layers.Dense(tamanio_salida, activation='softmax')  # capa salida\n",
    "])\n",
    "\n",
    "# Crear el optimizador con la tasa de aprendizaje especificada\n",
    "optimizador = Adam(learning_rate=TASA_APRENDIZAJE)\n",
    "\n",
    "# Compilamos el modelo\n",
    "modelo.compile(optimizer=optimizador, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Entrenar el modelo\n",
    "print(f\"Entrenando modelo con TAMANIO_TANDA={TAMANIO_TANDA}, TAMANIO_CAPA_ESCONDIDA={TAMANIO_CAPA_ESCONDIDA}, TASA_APRENDIZAJE={TASA_APRENDIZAJE}, NUMERO_EPOCAS={NUMERO_EPOCAS}...\")\n",
    "start = time.time()\n",
    "historia = modelo.fit(datos_entreno, epochs=NUMERO_EPOCAS, validation_data=datos_validacion, verbose=1)\n",
    "end = time.time()\n",
    "tiempo_entrenamiento = end - start\n",
    "print(\"Listo!\")\n",
    "\n",
    "# Obtener la pérdida\n",
    "print(\"Evaluando modelo...\")\n",
    "perdida_prueba, precision_prueba = modelo.evaluate(datos_prueba)\n",
    "\n",
    "# Obtener la precisión de prueba final\n",
    "precision_entrenamiento = historia.history['accuracy'][-1]\n",
    "\n",
    "# Obtener la precisión de validación final\n",
    "precision_validacion = historia.history['val_accuracy'][-1]\n",
    "\n",
    "# Guardar los resultados\n",
    "results.append({\n",
    "    \"Tasa de aprendizaje\": tasa,\n",
    "    \"Precisión de entrenamiento\": \"{:.2f}%\".format(precision_entrenamiento * 100),\n",
    "    \"Precisión de prueba\": \"{:.2f}%\".format(precision_prueba * 100),\n",
    "    \"Precisión de validación\": \"{:.2f}%\".format(precision_validacion * 100),\n",
    "    \"Tiempo de entrenamiento (s)\": \"{:.2f}\".format(tiempo_entrenamiento)\n",
    "})\n",
    "\n",
    "# Mostrar resultados como dataframe\n",
    "df = pd.DataFrame(results)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
